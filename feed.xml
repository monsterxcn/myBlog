<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Monstx's Blog</title>
        <link>https://blog.monsterx.cn/</link>
        <description>Monsterx CN - 学生 / 前端 / 电气</description>
        <lastBuildDate>Sun, 01 Nov 2020 12:04:38 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>Gridsome Feed Plugin</generator>
        <atom:link href="https://blog.monsterx.cn/feed.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[手帐 · 封锁之下]]></title>
            <link>https://blog.monsterx.cn/life/heu-in-amazing-walls/</link>
            <guid>https://blog.monsterx.cn/life/heu-in-amazing-walls/</guid>
            <pubDate>Wed, 30 Sep 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>本来 22 日打算就学校疫情防控下某一奇幻行为发表批评的声音，结果由于一些个人原因稿子写了一半放弃了。今天看到自己冷清的博客心里有点失落，索性将旧的手稿改写成一篇手帐。</p>
<h2 id="生活">生活</h2>
<p>开学接近一个月，我正逐渐习惯在学校尚未解封的情况下生活。</p>
<p>封校对我而言其实并没有什么太大的影响，网购的东西依旧能送到菜鸟驿站，衣食住行基本都有解决的办法。只不过点外卖变麻烦了、不能和朋友出校聚餐、看热门电影了。乐观点，这些封锁倒是让我省下了不少生活费，在学习上花的功夫也前所未有的多了（当然也不排除我想到毕业时的焦虑情绪影响）。一个月的时间，我需要准备因疫情延误的上学期期末考试，其中的后两个月备考同时还需要学麻烦的专业课程。室友说考研大概就是这种感觉吧，每天都要在崩溃边缘挣扎。于我而言倒也没有那么夸张，因为一些实在是难懂的专业选修课我干脆抛开了。我每天不用考虑吃什么、去哪里，早晨起床就去食堂喝一碗朴素的粥，接着在图书馆、教学楼找位置看书。上午结束了就再去食堂找个人少的窗口打点饭菜，狼吞虎咽吃完回寝室休息一会，又接着开始一下午的耕耘。晚饭也是和中午一样，但是会换个窗口换个口味。晚上接着去白天学习的位置，9 点多回寝室唠唠嗑、看看稀奇古怪的应用推送，洗脚睡觉！当然这是最理想的情况，实际我还有一些时间花在了睡觉和发呆上。</p>
<p>前两周我坚持的还算可以，后两周由于开始正式上课了，复习备考的时间几乎都被压榨干净，整个人也疲倦了许多。</p>
<p>周一一整天都是补上疫情耽误的工程实践课，三个周一分别练习车削、特种加工、电子工艺。车削车床简直是我的噩梦，蜗杆正转还是反转我根本记不住，在老师的手把手指导下我成功表演了正反转不分、瞎旋进旋出，车了一个端面后人就宕机了。还好这是两人一组用一个车床，我队友一个人就车了一个全组最光滑的作品。特种加工倒还蛮简单，画一个平面图用 3B 代码模拟切割测试通过即可，旁边的人在画守望先锋里的武器，我想了半天也没想出来能画个什么，最后就对着哔哩哔哩的标志画了一个小电视的轮廓交上去。3B 代码写起来十分无脑，不需要什么逻辑处理，就是简单的算几个参数交给机器划线，无敌的我完成了自己的还帮同桌写了一份，成就感满满。电子工艺就是烙铁实践，时隔两年我再次拿起烙铁，心里五味杂陈。曾经还许诺自己做个科创大佬，现在啥也不是，连烙铁用起来都技不如人。</p>
<p>周二是从早上八点上到晚上八点的辛苦日，上午工程电磁场原理课讲偏工程实际的电磁场的一切理论，是咱学校电气工程的基础课。接下来新时代习思想课，最先只有黑龙江省和北京上海开设的思政课程。上午的课程约莫十二点结束，一个半小时后下午的课开始了。电力电子技术，是模电数电大类之外的电子技术理论，才开始讲六大电力电子器件，接下来会讲交流与直流四大类基本变换：整流、逆变、斩波、调压。电力系统分析，电气工程专业课，分析电力系统的理论目前正在讲电力系统的数学模型、潮流计算。「潮流」是电力系统的专业名词之一，「手工算潮流」实际是讲给出某些值求解这个电力系统中任意一点的运行状态。这些课程听起来都蛮有专业的感觉，虽然不像数学物理理论那样抽象，但实际用到的都是这些基础知识（尤指电路），公式不好记且需要理解推导过程。电气工程这一体系在这些课程的讲解下逐渐现出轮廓，我深深感觉到高等数学、物理、电路基础知识在更加高深的理论中重要性。这些专业课普遍需要复变、电路的知识来支撑，各种数学模型、等效电路如果没有这些基础理解起来十分难懂。</p>
<p>周三周四周五除了上面的课还有数字电子技术和自动控制原理。数电还算可以听懂，正在讲一些逻辑电路。数电老师十分关心坐在后排学生的听课体验，课前经常在教室后面和同学唠嗑，鼓励大家往前坐。这好像是我第一次注意到咱学校有这样的老师。自动控制原理，咱学校的考研课，用数学模型分析计算传统控制系统的性能。刚听起来这段时间和我上学期选修的数字信号处理有点相同的感觉，用数学函数表示输入信号输出信号，讲课过程中傅里叶变换、拉普拉斯变换张口就来，听了几节课我就完全蒙了。</p>
<p>专业选修课已经开课的只有可编程控制器，讲的是用只有中国地区还在用的西门子 S7-200/300 控制器做小项目比如物块分拣、电梯什么的，实验课的占比很大，很多课都像这样不仅在理论上要求掌握，在动手实验的能力要求上也没有丢下。简单来说就是水课没得了。</p>
<h2 id="读书">读书</h2>
<p>繁重的学习任务让我这个月牺牲了很多娱乐摸鱼的时间。但从这个学期开始，我读书了！</p>
<p>中旬我在校图书馆借了一本《三体》，这是我一直想读的书。高三时就买了全套纸质书，还有银河帝国的全套，信誓旦旦计划要在高考之后好好读，结果后来时间全花在了追剧看电影上，三体也只看了第一部汪淼玩「三体」游戏的那几章。开学来打算将家里的书带过来，奈何行李太重了，小说就被我抛弃了。在图书馆借完书当天晚上我找了个座位看三体，越看越着迷，一直到九十点才回寝，旁边的数字信号处理书一页都没翻。三体第一部按我的总结是以纳米材料科学家汪淼的视角讲述了叶文洁在文革前后在红岸基地（和后来的第二红岸基地）与三体人建立联系并成立了地球三体组织、准备迎接三体舰队的故事。</p>
<p>大部分时候，我对看书其实并不太感兴趣。小的时候喜欢看那些传说神话之类，读起来也许潜移默化中改变了自己的价值观、但最主要的还是感觉故事情节有趣。后来我也只是在《少年博览》《科学 FANS》中找故事读，没怎么读过文学著作。这大概就是为啥现在的我品味素质修养都不太高的原因吧。初三读过《斗罗大陆》第一部，高中读了一点点《雪中悍刀行》，这些书我觉得都不是拿得上台面的，让老师看见了指定要被没收而且批评。而《三体》作为屡屡获奖的科幻文学作品，其中的物理知识给人一种「亦真亦幻」的感觉，就算让老师逮着了应该情节也不能算太严重。读完第一部三体之后我接着借来了李淼的《〈三体〉中的物理学》给自己深度扫盲，借刘慈欣为李淼作序《比科幻更神奇的科学》中的一句话为这本书做总结：</p>
<blockquote>
<p>他（李淼）并没有像一般的读者和网友一样，专注于挑小说中的硬伤（在这方面他无疑是最有资格的），而是以《三体》中的科幻内容作为引子和起点，描绘了一幅现代物理学和宇宙学的宏伟图景。</p>
</blockquote>
<p>这本科普我目前才读了一半，我对后面李淼「从物理学的角度」探讨「自由意志」的命题十分期待。我越发觉得数学、物理基础学科是如此的神圣，只有天才才能掌握吧。</p>
<p>借到三体第一部之后一天我把所有的复习工作都推了，一心读三体，驰骋在浩瀚宇宙中希望有一天自己也能到达那里。第一部读完之后我立刻去借了第二部并且以更甚的热情读完了，罗辑的那句「我对三体世界说话」真是太震撼了！最后一章，人类面对比自己强大无数倍的三体世界几乎没有丝毫战胜的希望，唯一的面壁人罗辑作为最后希望也失去了人类的信任，但即使这样被人类驱逐的罗辑还是扭转了局势建立「威慑」。这一部中刘大对宇宙文明法则的思考我觉得堪比阿西莫夫机器人三大定律，太神了！如我在众多日漫中力推《进击的巨人》一样，《三体》也将是我在科幻文学的前排推荐。</p>
<p>第三部在图书馆没有借到，我便借了另外一些书，比如《冰与火之歌》《梦的解析》《黄衣王》。《冰与火之歌》是 HBO 权游的原著，《梦的解析》大概是每个心理学学者必读书籍，《黄衣王》大概是和「克苏鲁」一个范畴的小说。其实还打算借猫腻的《庆余年》和紫金陈的《长夜难明》，但这两本都借不到，估计是改编电视剧热播带动的吧。</p>
<p>我真恨，为什么前两年花了那么多时间在看无意义的视频上？</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[为 Gridsome 添加 Artalk 自托管评论系统]]></title>
            <link>https://blog.monsterx.cn/code/use-self-hosted-comment-system-in-gridsome/</link>
            <guid>https://blog.monsterx.cn/code/use-self-hosted-comment-system-in-gridsome/</guid>
            <pubDate>Fri, 21 Aug 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>本文介绍在 Gridsome 博客中启用 Artalk 自托管评论系统的方法。欢迎尝试这款小众的、漂亮的评论系统！</p>
<p>刚开这个小站时打算一劳永逸吃上 Disqus 这块香饽饽，结果没两天我的宝贝室友就跟我说：你站怎么没法评论啊？我深思熟虑之后决定还是不用 Disqus 了。换 Gitalk？不行不行，Gitalk 虽好但是每一个新站点都需要 GitHub 账号授权一次，而且国内访问也体验不佳。Valine 之流我不太喜欢，其他的评论系统我都不甚了解。那该何去何从呢？</p>
<h2 id="选择-artalk-的理由">选择 Artalk 的理由</h2>
<p>由于水平不足，我是没法自己写一个评论系统的，于是我决定在友链 <a href="https://qwqaq.com/">@QWQAQ</a> 和 <a href="https://www.ouorz.com/">@TonyHe</a> 两位大佬的两个评论系统里选一个，要知道缝合代码、借用轮子这种事我最擅长了。那么是用 <a href="https://github.com/qwqcode/Artalk">@qwqcode/Artalk</a> 还是 <a href="https://github.com/HelipengTony/nexment">@HelipengTony/nexment</a> 呢？</p>
<p>外行人看热闹，我以一个前端菜鸟的水平不足以在架构上对两个评论系统做出优劣比较，所以以下只是我个人选择的理由。</p>
<p>Nexment 是 <del>React.js 编写</del> 「计划全平台、全框架适配」的基于 LeanCloud 实现 Serverless 的评论系统，官方提供了 React.js 和 Vue.js 示例，有自己的文档（虽然 Tony 好像还没有写详细，但至少有一个站点在那）。官方示例站点 <a href="https://nexment-demo.ouorz.com/">Nextment for React Demo</a> / <a href="https://nexment-vue-demo.ouorz.com/">Nextment for Vue Demo</a>，我觉得新颖的点在弹窗显示多级评论上，在我逛的博客圈子里比较少见。部署的话需要提前配置 LeanCloud 的数据库，这让我停止了思考（我的数据库放在别人那里想想就不靠谱啊喂）。Nexment 诞生于最近一月，截至本文发布前最后一次提交在三天前，作者 TonyHe 感觉是个努力 Coding 的巨佬，毕竟即将出国留学了。</p>
<p>Artalk 是 TypeScript 编写的需要自行部署后端的「一款简洁有趣的自托管评论系统」，数据存放在 JSON 文件中，后续听说也计划增加 MySQL 的支持（我：那样听起来就不太简洁了呢）。需要自行搭建后端估计劝退了很多人，而且目前只支持 PHP 后端，README 里写的 Go、Node.js、Python 后端均迟迟未上线。官方给的示例只有几个 HTML，相当的「简洁」，基本都是在 HTML 引入 <code>Artalk.css</code> <code>Artalk.js</code> 后一些简单的配置。官方示例站点 <a href="https://artalk.js.org/">Artalk DEMO</a>，听说在这里可以观察到开发者立 Flag 现场。Artalk 诞生于 2018 年 10 月，截至本文发布前最后一次提交在今年 5 月，考虑到作者 QWQAQ 的学业繁忙，摸鱼也是可以理解的。</p>
<p>简单了解两个评论系统之后，再看自身的 Gridsome 平台，基于 Vue.js。怎么看我都应该选择 Nexment，但是我却选择了 Artalk。原因嘛，自然是图个简单。Artalk 之前就搭建了自己的后端使用过一段时间，官方搭配的滑稽表情包在别的评论系统一众阿鲁表情包、贴吧表情包中独树一帜。更重要的是 Artalk 的代码我能看懂一些，进行自定义修改很方便。Nexment 虽好，但是外观相比 Artalk 我还是更喜欢后者，弹窗多级评论显示对我来说也需求不高，要我看 React.js 项目代码更是劝退。</p>
<h2 id="对-artalk-的修改">对 Artalk 的修改</h2>
<p>Artalk 目前还没有支持夜间模式，原本的样式和本站也不太搭。于是我 Fork 了一份代码针对这两个问题进行修改。</p>
<p>夜间模式主要按照当前主题和部分 Disqus 的配色、样式进行调整。其实之前也尝试配过一个夜间模式，用在自己修改后的 Typecho 主题上，但是代码过于粗糙。我调整颜色的方法甚至是直接将原版压缩后的 <code>.css</code> 打开后按 <code>Ctrl</code> <code>F2</code> 全部替换！剩下的样式代码压缩后即使找工具美化也看的我云里雾里。这次直接克隆仓库安装依赖从源头编译，方便那不是一星半点！</p>
<p>到本文发布为止，我共进行了十余次提交，主要对以下这些地方进行了修改：</p>
<ul>
<li>夜间模式</li>
<li>小屏幕样式部分适配</li>
<li>评论显示效果嵌套层数自定义</li>
<li>控制台版权去除</li>
<li>「Power By Artalk」 调整</li>
<li>侧边栏通知中心细节调整</li>
</ul>
<p>夜间模式的配色均在 <a href="https://github.com/monsterxcn/Artalk/blob/master/src/css/_variables.less">_variables.less</a> 中定义，以 <code>--at-</code> 为前缀。GitHub 仓库地址 <a href="https://github.com/monsterxcn/Artalk">@monsterxcn/Artalk</a>，我搭了个示例站点 <a href="https://artalk.vercel.app">Artalk ♂</a>。我没有系统学过 CSS 写法，所以让本应简洁的代码变得不简洁了，希望各位多发挥才智、创作自己的二次开发版 Artalk！<del>今天发现评论区的 <code>&lt;pre&gt;</code> 代码块样式还存在问题，</del> 探索中 😣……</p>
<h2 id="在-gridsome-上调试">在 Gridsome 上调试</h2>
<p>刚使用 Gridsome 大约一周，对它的了解很少，Vue.js 水平连门都入不了。但是这样的我还是花了几个小时将 Artalk 成功适配到了博客。中间踩了几个坑在这里提一下解决方法。</p>
<h3 id="安装-artalk">安装 Artalk</h3>
<p>Artalk 提供了 npm 包，所以可以直接在命令行安装</p>
<pre><code class="language-bash">npm install artalk --save</code></pre>
<p>如果需要安装我修改之后的版本则需要在 <code>package.json</code> 中手动写入仓库地址：</p>
<pre><code class="language-diff">{
  &quot;name&quot;: &quot;gridsome-starter-blog&quot;,
  &quot;private&quot;: true,
  &quot;scripts&quot;: {
    &quot;build&quot;: &quot;gridsome build&quot;,
    &quot;develop&quot;: &quot;gridsome develop&quot;,
    &quot;explore&quot;: &quot;gridsome explore&quot;
  },
  &quot;dependencies&quot;: {
    &quot;@gridsome/plugin-google-analytics&quot;: &quot;^0.1.0&quot;,
    &quot;@gridsome/remark-prismjs&quot;: &quot;^0.2.0&quot;,
    &quot;@gridsome/source-filesystem&quot;: &quot;^0.6.0&quot;,
    &quot;@gridsome/transformer-remark&quot;: &quot;^0.3.0&quot;,
-   &quot;gridsome&quot;: &quot;^0.7.0&quot;
+   &quot;gridsome&quot;: &quot;^0.7.0&quot;,
+   &quot;artalk&quot;: &quot;https://github.com/monsterxcn/Artalk.git&quot;,
  },
  &quot;devDependencies&quot;: {
    &quot;node-sass&quot;: &quot;^4.12.0&quot;,
    &quot;sass-loader&quot;: &quot;^8.0.0&quot;
  }
}</code></pre>
<p>这里 L16 会直接引用我修改后的最新开发版，但是如果用于自动构建发布站点的 GitHub Actions 中使用了依赖缓存，则总是使用第一次执行工作流时安装的版本，无法获得后续更新。<del>为了解决这一问题，将 Git 链接修改为指定 commit 时刻的地址即可</del> 这好像也不可行。</p>
<h3 id="引入-artalkcss">引入 <code>Artalk.css</code></h3>
<p>接下来引用 <code>Artalk.css</code> 和 <code>Artalk.js</code>，建议单独新建 <code>ArtalkCards.vue</code> 文件存放 Artalk 评论组件的代码，只在该模板中引入 <code>Artalk.css</code> 即可。</p>
<pre><code class="language-javascript">import &#39;artalk/dist/Artalk.css&#39;</code></pre>
<p>当前不必要的 <code>.css</code> 文件我们都让它在不得不引入时再加载。</p>
<h3 id="引入-artalkjs">引入 <code>Artalk.js</code></h3>
<p>最初引入 <code>Artalk.js</code> 时，我参考主题使用 DisqusJS 的方法在 <code>.vue</code> 模板文件的 <code>&lt;script&gt;</code> 标签中这样写：</p>
<pre><code class="language-javascript">import &#39;artalk/dist/Artalk.css&#39;
import Artalk from &#39;artalk&#39;

export default {

  // ...

  mounted() {
    // Initialize post comment by Artalk
    if (process.env.NODE_ENV === &#39;production&#39;) {
      var artalk = new Artalk({
        el: &#39;#artalkcomments&#39;,
        placeholder: &#39;说点什么 (づ￣ 3￣)づ&#39;,
        defaultAvatar: &#39;mp&#39;,
        // maxNest: 2,
        pageKey: &#39;https://blog.monsterx.cn/some-page/&#39;,
        serverUrl: &#39;https://lab.monsterx.cn/ArtalkServer&#39;,
        readMore: {
          pageSize: 15,
          autoLoad: true,
        },
      })
    }
  },
}</code></pre>
<p><code>gridsome develop</code> 预览正常，但是发布时遇到「ReferenceError: window is not defined」，提示的报错信息都来自 <code>node_modules/artalk/dist/Artalk.js</code>，我以为是自己修改 Artalk 出的问题，于是又回去修改 Artalk 代码，将网上用来解决这个问题的几个方法都试了一遍依旧报错。正当我迷惑时，突然想到了 Gridsome 的源头 Vue.js 本身，于是我一拍脑袋在搜索时加了关键词 <code>gridsome</code>，这才发现原来和「Client API」有关。</p>
<p>几个参考链接《<a href="https://stackoverflow.com/questions/40707481/window-is-not-defined-in-vue-js-2">javascript - &#39;window&#39; is not defined in Vue.js 2 - Stack Overflow</a>》《<a href="https://github.com/gridsome/gridsome/issues/646">Failed to render / ReferenceError: window is not defined (vue2-leaflet) - issue #646 - GitHub @gridsome/gridsome</a>》《<a href="https://gridsome.org/docs/client-api/#isclient">Client API - Gridsome</a>》</p>
<p>虽然不知道这是个什么东西，但是大概说的是有些代码只能在客户端跑，服务端无法 <del>执行</del>「渲染」，比如 <code>window</code> 的操作。要说专业点，应该是关乎 S(erver) S(ide) R(ender)「服务器端渲染」的机制。根据上面第二个链接中 <a href="https://github.com/gridsome/gridsome/issues/646#issuecomment-578367659">IHIutch 的回答</a>，成功找到了解决方案：</p>
<pre><code class="language-diff">import &#39;artalk/dist/Artalk.css&#39;
-import Artalk from &#39;artalk&#39;

export default {

  // ...

  mounted() {
    // Initialize post comment by Artalk
    if (process.env.NODE_ENV === &#39;production&#39;) {
+     let Artalk = require(&#39;artalk&#39;)
      var artalk = new Artalk({
        el: &#39;#artalkcomments&#39;,
        placeholder: &#39;说点什么 (づ￣ 3￣)づ&#39;,
        defaultAvatar: &#39;mp&#39;,
        // maxNest: 2,
        pageKey: &#39;https://blog.monsterx.cn/some-page/&#39;,
        serverUrl: &#39;https://lab.mocurio.com/artalk/&#39;,
        readMore: {
          pageSize: 15,
          autoLoad: true,
        },
      })
    }
  },
}</code></pre>
<p>L10 <code>process.env.NODE_ENV === &#39;production&#39;</code> 和 <code>process.isClient</code> 实际体验应该都差不多。上面两处注释掉的 <code>maxNest</code> 是我修改后具有的功能，原版开启后不会有效果，该项不设置时默认显示三层嵌套。</p>
<h2 id="最终模板">最终模板</h2>
<p><del>在 <code>/src/components</code> 新建 <code>ArtalkCards.vue</code> 作为 Artalk 评论区模板</del> 我对 Gridsome 的模板还不太熟悉，总之直接在需要引入评论区的页面直接加好了：</p>
<pre><code class="language-html">&lt;template&gt;

  &lt;!-- --&gt;

  &lt;div class=&quot;artalk-cards&quot;&gt;
    &lt;details class=&quot;admonition admonition-warning&quot;&gt;
      &lt;summary&gt;
        Comment on this blog
      &lt;/summary&gt;
      &lt;p&gt;
        评论如无特殊原因均不会被删除，提交前请三思。&lt;br /&gt;
        你应该懂得如何发表适当的观点，请对自己的言论负责。
      &lt;/p&gt;
    &lt;/details&gt;
    &lt;div id=&quot;LetsArtalk&quot;&gt;&lt;/div&gt;
  &lt;/div&gt;

  &lt;!-- --&gt;

&lt;/template&gt;

&lt;script&gt;
// ...

import &#39;artalk/dist/Artalk.css&#39;

export default {

  // ...

  mounted() {

    // ...

    // Initialize post comment by Artalk
    if (process.env.NODE_ENV === &#39;production&#39;) {
      let Artalk = require(&#39;artalk&#39;)
      var artalk = new Artalk({
        el: &#39;#LetsArtalk&#39;,
        placeholder: &#39;说点什么 (づ￣ 3￣)づ&#39;,
        defaultAvatar: &#39;mp&#39;,
        // maxNest: 2,
        pageKey: &#39;https://blog.monsterx.cn&#39; + this.$page.post.path,
        serverUrl: &#39;https://lab.monsterx.cn/ArtalkServer&#39;,
        readMore: {
          pageSize: 15,
          autoLoad: true,
        },
      })
    }
  },
}
&lt;/script&gt;

&lt;page-query&gt;
query Post ($id: ID!) {

  // ...

  post: post (id: $id) {
    path
  }
}
&lt;/page-query&gt;

&lt;style lang=&quot;scss&quot;&gt;
.artalk-cards {
  background: var(--at-bg-main);
  border-radius: var(--radius);
  max-width: var(--content-width);
  margin: 20px auto 100px;
  box-shadow: 1px 1px 5px 0 rgba(0, 0, 0, 0.02),
    1px 1px 15px 0 rgba(0, 0, 0, 0.03);
  details {
    margin: 0 auto;
    text-align: center;
    border-top-left-radius: var(--radius);
    border-top-right-radius: var(--radius);
    font-weight: 600;
    outline: none;
    summary {
      list-style: none;
      margin: 4px auto !important;
      color: var(--cb-admonition-icon-color) !important;
      margin: 2.75rem 0 1rem;
      font-family: var(--title-font-family);
      line-height: 1.5;
      outline: none;
    }
    summary::-webkit-details-marker {
      display: none;
    }
    p {
      color: var(--at-font-color);
      margin-bottom: 0;
    }
  }
  #LetsArtalk {
    padding: 20px;
  }
  @media screen and (max-width: 767.5px) {
    details &gt; p {
      text-align: left;
    }
    #LetsArtalk {
      padding: 20px 0 0 0;
    }
  }
}

/** */
&lt;/style&gt;</code></pre>
<p>根据需要自己修改下 <code>&lt;template&gt;</code> 的内容，注意保证只存在一个「主标签」，比如我的是 <code>&lt;div class=&quot;artalk-cards&quot;&gt;</code>。修改 L29-37 为自己的 Artalk 参数，<code>pageKey</code> 需要自行拼接为页面 URL，否则后端发送的邮件中「查看回复」按钮可能链接到奇怪的地方导致体验极差，其他参数查阅 <a href="https://github.com/monsterxcn/Artalk/blob/master/types/artalk-config.d.ts">artalk-config.d.ts</a>。<code>&lt;style&gt;</code> 是我针对当前主题做的一点适配。</p>
<p>考虑到能看到这里并且有意愿尝试 Artalk 的人应该极少，我悄悄说一句大家可以使用我搭的 Artalk PHP 后端尝尝鲜吖，它运行在阿里云 <del>北京</del> 上海学生机，并发访问除了我自己的站点应该就没了，而我自己的站点访问也很少，所以服务器压力不大，给大家玩玩还是可以的。将配置中的 <code>serverUrl</code> 字段填写为 <code>https://lab.monsterx.cn/ArtalkServer</code> 来使用本站后端，跨域访问目前允许，不必向我申请。</p>
<blockquote>
<p>其实通过 phpcomposer 安装搭建 Artalk PHP 后端也十分简单。目前发现需要注意的是 PHP 得开启 GD 库和 FreeType 支持，否则无法生成图形验证码。<br />
使用别人的后端存在一些不足之处：邮件模板、发信设置只能使用搭建者的，目前 Artalk 对多站点的支持尚不完整。<br />
担心引用本站后端存在数据安全或其他问题可以尝试自行搭建。<del>以后有空可能写一篇 Docker Artalk PHP 后端的文。</del> 如果对上述内容有问题欢迎留言。</p>
</blockquote>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub README.md 显示博文并自动更新]]></title>
            <link>https://blog.monsterx.cn/code/update-your-posts-in-readme/</link>
            <guid>https://blog.monsterx.cn/code/update-your-posts-in-readme/</guid>
            <pubDate>Tue, 18 Aug 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>今年 GitHub 推出了 profile-level README 的新特性，只要新建与用户名同名仓库并创建 <code>README.md</code> 就可以在 GitHub 个人主页上看到其内容。比起单纯的固定仓库或 Gist 在个人主页，我觉得这会让 GitHub 主页变得更多姿多彩，戳官方 <a href="https://docs.github.com/en/github/setting-up-and-managing-your-github-profile/managing-your-profile-readme">文档</a> 了解更多。然而，像我这种菜鸟想了很久都没有想清楚在个人主页上到底写点什么，拿得出手的项目是不存在的，刷 commit 也只是满足下自己的虚荣心而已，能力提升微乎其微。</p>
<p>这段时间看了很多个人介绍仓库之后，发现我想多了：GitHub 是什么？<del>全球最大的同性交友网站啊！</del> 又不是世纪佳缘，写得漂亮能找着对象吗？开心就好，介绍下自己，放张关于自己仓库的小卡片，留点 E-mail Twitter 之外更丰富的社交链接，这个 <code>README.md</code> 就达标辣！（靠 GitHub 找工作的话那当我没说。</p>
<p>单单写 READMD 没什么好记录的，本文就记录一下自己为了让 README 稍稍有点逼格，制作「从 RSS 获取最近更新并以 Markdown 格式写入 README」功能的经过吧。毕竟对于萌新我来说，做出点有意思的东西是很有成就感的。</p>
<blockquote>
<p>写着写着就变成了幼儿读物的感觉，请不要笑话我了，毕竟我是个萌新，阿巴阿巴 🤪 <br />
看完这篇文章你至少会了解到「萌新如何开始学习别人的代码」「GitHub Actions 如何跨仓库执行」「从 <code>workflows_run</code> 触发工作流」</p>
</blockquote>
<h2 id="从文章中学习">从文章中学习</h2>
<p>一切是从这里开始的：《<a href="https://simonwillison.net/2020/Jul/10/self-updating-profile-readme/">Building a self-updating profile README for GitHub - Simon Willison’s Weblog</a>》，这位作者的仓库 <a href="https://github.com/simonw/simonw">@simonw/simonw</a> 显示了三栏自动更新的内容，包括 GitHub 上的打包发布、博客文章和另外一个站点 T(hings) I L(earned) 的条目。这三栏分别使用了三种途径获取最新内容的，均由 Python 实现：</p>
<ul>
<li>「GitHub GraphQL API -&gt; python_graphql_client -&gt; Latest Release」</li>
<li>「RSS Atom feed -&gt; feedparser -&gt; Latest posts」</li>
<li>「Datasette API -&gt; SQL query -&gt; Latest entries」</li>
</ul>
<p>第一个和第三个我都不了解，只有 RSS 的格式稍微懂一点，巧的是这正好能用来获取博客最新的文章。动手开始！</p>
<h2 id="面向谷歌编程">面向谷歌编程</h2>
<p>查看仓库现成的 <code>build_readme.py</code> 文件，一眼扫下来有 218 行，有点晕。一遍看下来 GitHub GraphQL API 和 Datasette API 相关的占了较大篇幅，这说明通过 RSS 获取博客内容的代码较少。这时候我选择找到第一个版本的文件，我觉得最初的版本大概率应该是最简陋的，能让我最快的搞清楚代码的大体结构。第一个版本的 <a href="https://github.com/simonw/simonw/commit/d2b5e8ba30b0d2b1a867e0bfafa1215a2b5ef287#diff-b8502c56279bd4ac52ccb69f70e81a13">build_readme.py</a> L139，就从这里开始吧。</p>
<details><summary><strong>从零开始学 Copy</strong></summary><br />


<p>从 L107 <code>if __name__ == &quot;__main__&quot;</code> 处开始读，截取在下面 L1。这句相当于 C 语言的 <code>int main()</code>（尝试白嫖腾讯云无服务器环境的时候从环境设置里学到的。</p>
<pre><code class="language-python">if __name__ == &quot;__main__&quot;:
    readme = root / &quot;README.md&quot;
    releases = fetch_releases(TOKEN)
    releases.sort(key=lambda r: r[&quot;published_at&quot;], reverse=True)
    md = &quot;\n&quot;.join(
        [
            &quot;* [{repo} {release}]({url}) - {published_at}&quot;.format(**release)
            for release in releases[:10]
        ]
    )
    readme_contents = readme.open().read()
    rewritten = replace_chunk(readme_contents, &quot;recent_releases&quot;, md)

    tils = fetch_tils()
    tils_md = &quot;\n&quot;.join(
        [
            &quot;* [{title}]({url}) - {created_at}&quot;.format(
                title=til[&quot;title&quot;],
                url=til[&quot;url&quot;],
                created_at=til[&quot;created_utc&quot;].split(&quot;T&quot;)[0],
            )
            for til in tils
        ]
    )
    rewritten = replace_chunk(rewritten, &quot;tils&quot;, tils_md)

    entries = fetch_blog_entries()[:10]
    entries_md = &quot;\n&quot;.join(
        [&quot;* [{title}]({url}) - {published}&quot;.format(**entry) for entry in entries]
    )
    rewritten = replace_chunk(rewritten, &quot;blog&quot;, entries_md)

    readme.open(&quot;w&quot;).write(rewritten)</code></pre>
<p><code>release</code> <code>til</code> 命名的很显然是获取 GitHub 和 TIL 最新内容相关，于是获取博客更新的主要代码就筛选出来了：L1-2 L27-33。L2 用到的变量 <code>root</code> 并没有出现定义，接下来找他的定义和用到的函数 <code>fetch_blog_entries()</code> <code>replace_chunk()</code>。</p>
<pre><code class="language-python">root = pathlib.Path(__file__).parent.resolve()    # 库 pathlib

## ...

def replace_chunk(content, marker, chunk):
    r = re.compile(                               # 库 re
        r&quot;&lt;!\-\- {} starts \-\-&gt;.*&lt;!\-\- {} ends \-\-&gt;&quot;.format(marker, marker),
        re.DOTALL,
    )
    chunk = &quot;&lt;!-- {} starts --&gt;\n{}\n&lt;!-- {} ends --&gt;&quot;.format(marker, chunk, marker)
    return r.sub(chunk, content)

## ...

def fetch_blog_entries():
    # 库 feedparser
    entries = feedparser.parse(&quot;https://simonwillison.net/atom/entries/&quot;)[&quot;entries&quot;]
    return [
        {
            &quot;title&quot;: entry[&quot;title&quot;],
            &quot;url&quot;: entry[&quot;link&quot;].split(&quot;#&quot;)[0],
            &quot;published&quot;: entry[&quot;published&quot;].split(&quot;T&quot;)[0],
        }
        for entry in entries
    ]</code></pre>
<p>看起来有些许复杂，此时应该提取出用到的 Python 库，实际调试的时候只要尝试单独运行这些代码块会得到未定义之类的错误，然后就能定位到缺失的库。在 Python 文件开头使用 <code>import</code> 导入。</p>
</details><br />


<p>下面是正式的面向谷歌编程，也就是学习用轮子（作者用到的那些库 pathlib、re、feedparser）：pathlib 库看起来没有需要谷歌的，一个能获取文件路径的库。re 库用到了正则表达式，结合作者在仓库第一版 <code>README.md</code> 中写的 <code>&lt;!-- blog starts --&gt;</code> <code>&lt;!-- blog ends --&gt;</code> 这样的标记，不难理解是将结果通过正则匹配找到位置，然后进行替换。feedparser 库从一个 Atom 链接获取了包含文章信息的数组，是为「源头」。</p>
<h3 id="feedparser-解析-rss">feedparser 解析 RSS</h3>
<p>《<a href="https://vimsky.com/article/4399.html">在 Python 中使用 Feedparser 解析 RSS - 纯净天空</a>》一篇足矣，或者看英文版《<a href="https://www.pythonforbeginners.com/feedparser/using-feedparser-in-python">Using Feedparser in Python - PythonForBeginners</a>》。当然，RSS 文件也要有一丢丢了解。XML 格式由 HTML 触类旁通不难理解，可以试着戳 <a href="https://blog.monsterx.cn/feed.xml">这里</a> 看看本站的 RSS 源格式。在每个 <code>&lt;item&gt;</code> 中包含了 <code>&lt;title&gt;</code> <code>&lt;link&gt;</code> <code>&lt;pubDate&gt;</code>，用来输出到 <code>README.md</code> 够了。</p>
<p>参考链接文章用的是 <code>dic[&#39;feed&#39;]</code> 这种格式，用起来和 <code>dic.feed</code> 是一样的，就用后面这种短一点的写个示例。</p>
<pre><code class="language-python">import feedparser

# 解析本站的 RSS 源
dic = feedparser.parse(&#39;https://blog.monsterx.cn/feed.xml&#39;)
channel = dic.feed                 # 获取 &lt;channel&gt; 数据
items = dic.entries                # 获取 &lt;item&gt; 数据
item = items[0]                    # 获取第一个 &lt;item&gt; 数据
sitetitle = channel.title          # 获取 &lt;channel&gt;&lt;title&gt; 数据
sitelink = channel.link            # 获取 &lt;channel&gt;&lt;link&gt; 数据
posttitle = items[0].title         # 获取 &lt;item&gt;&lt;title&gt; 数据
postlink = items[0].link           # 获取 &lt;item&gt;&lt;link&gt; 数据
postdate = items[0].published      # 获取 &lt;item&gt;&lt;pubDate&gt; 数据

print(sitetitle)</code></pre>
<p>RSS 数据较多时 <code>print(dic)</code> 可能让人头皮发麻，自行体会吧。下面给出更直观的对比：</p>
<pre><code class="language-html">&lt;rss xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:content=&quot;http://purl.org/rss/1.0/modules/content/&quot; xmlns:atom=&quot;http://www.w3.org/2005/Atom&quot; version=&quot;2.0&quot;&gt;
    &lt;channel&gt;
        &lt;title&gt;Monstx&#39;s Blog&lt;/title&gt;
        &lt;link&gt;https://blog.monsterx.cn/&lt;/link&gt;
        &lt;description&gt;Monsterx CN - 学生 / 前端 / 电气&lt;/description&gt;
        &lt;lastBuildDate&gt;Tue, 18 Aug 2020 04:11:01 GMT&lt;/lastBuildDate&gt;
        &lt;docs&gt;https://validator.w3.org/feed/docs/rss2.html&lt;/docs&gt;
        &lt;generator&gt;Gridsome Feed Plugin&lt;/generator&gt;
        &lt;atom:link href=&quot;https://blog.monsterx.cn/feed.xml&quot; rel=&quot;self&quot; type=&quot;application/rss+xml&quot;/&gt;
        &lt;item&gt;
            &lt;title&gt;
                &lt;![CDATA[ New Start ]]&gt;
            &lt;/title&gt;
            &lt;link&gt;https://blog.monsterx.cn/life/new-start-with-gridsome/&lt;/link&gt;
            &lt;guid&gt;https://blog.monsterx.cn/life/new-start-with-gridsome/&lt;/guid&gt;
            &lt;pubDate&gt;Sat, 15 Aug 2020 00:00:00 GMT&lt;/pubDate&gt;
            &lt;content:encoded&gt;
                &lt;![CDATA[ &lt;p&gt;在这普通的一天，我穿着普通的鞋...&lt;/p&gt; ]]&gt;
            &lt;/content:encoded&gt;
        &lt;/item&gt;
        &lt;item&gt;
            &lt;!-- 另外一篇文章 --&gt;
        &lt;/item&gt;
        &lt;item&gt;
            &lt;!-- 另外一篇文章 --&gt;
        &lt;/item&gt;
    &lt;/channel&gt;
&lt;/rss&gt;</code></pre>
<p>解析后：</p>
<details><summary><strong>freeparser 解析结构</strong></summary><br />


<pre><code class="language-json">{
  &#39;feed&#39;: {
    &#39;title&#39;: &quot;Monstx&#39;s Blog&quot;, 
    &#39;title_detail&#39;: {
      &#39;type&#39;: &#39;text/plain&#39;, 
      &#39;language&#39;: None, 
      &#39;base&#39;: &#39;https://blog.monsterx.cn/feed.xml&#39;, 
      &#39;value&#39;: &quot;Monstx&#39;s Blog&quot;
    }, 
    &#39;links&#39;: [
      {
        &#39;rel&#39;: &#39;alternate&#39;, 
        &#39;type&#39;: &#39;text/html&#39;, 
        &#39;href&#39;: &#39;https://blog.monsterx.cn/&#39;
      }, {
        &#39;href&#39;: &#39;https://blog.monsterx.cn/feed.xml&#39;, 
        &#39;rel&#39;: &#39;self&#39;, 
        &#39;type&#39;: &#39;application/rss+xml&#39;
      }
    ], 
    &#39;link&#39;: &#39;https://blog.monsterx.cn/&#39;, 
    &#39;subtitle&#39;: &#39;Monsterx CN - 学生 / 前端 / 电气&#39;, 
    &#39;subtitle_detail&#39;: {
      &#39;type&#39;: &#39;text/html&#39;, 
      &#39;language&#39;: None, 
      &#39;base&#39;: &#39;https://blog.monsterx.cn/feed.xml&#39;, 
      &#39;value&#39;: &#39;Monsterx CN - 学生 / 前端 / 电气&#39;
    }, 
    &#39;updated&#39;: &#39;Tue, 18 Aug 2020 04:11:01 GMT&#39;, 
    &#39;updated_parsed&#39;: time.struct_time(tm_year=2020, tm_mon=8, tm_mday=18, tm_hour=4, tm_min=11, tm_sec=1, tm_wday=1, tm_yday=231, tm_isdst=0), 
    &#39;docs&#39;: &#39;https://validator.w3.org/feed/docs/rss2.html&#39;, 
    &#39;generator_detail&#39;: {&#39;name&#39;: &#39;Gridsome Feed Plugin&#39;}, 
    &#39;generator&#39;: &#39;Gridsome Feed Plugin&#39;
  }, 
  &#39;entries&#39;: [
    {
      &#39;title&#39;: &#39;New Start&#39;, 
      &#39;title_detail&#39;: {
        &#39;type&#39;: &#39;text/plain&#39;, 
        &#39;language&#39;: None, 
        &#39;base&#39;: &#39;https://blog.monsterx.cn/feed.xml&#39;, 
        &#39;value&#39;: &#39;New Start&#39;
      }, 
      &#39;links&#39;: [
        {
          &#39;rel&#39;: &#39;alternate&#39;, 
          &#39;type&#39;: &#39;text/html&#39;, 
          &#39;href&#39;: &#39;https://blog.monsterx.cn/life/new-start-with-gridsome/&#39;
        }
      ], 
      &#39;link&#39;: &#39;https://blog.monsterx.cn/life/new-start-with-gridsome/&#39;, 
      &#39;id&#39;: &#39;https://blog.monsterx.cn/life/new-start-with-gridsome/&#39;, 
      &#39;guidislink&#39;: False, 
      &#39;published&#39;: &#39;Sat, 15 Aug 2020 00:00:00 GMT&#39;, 
      &#39;published_parsed&#39;: time.struct_time(tm_year=2020, tm_mon=8, tm_mday=15, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=5, tm_yday=228, tm_isdst=0), 
      &#39;content&#39;: [
        {
          &#39;type&#39;: &#39;text/html&#39;, 
          &#39;language&#39;: None, 
          &#39;base&#39;: &#39;https://blog.monsterx.cn/feed.xml&#39;, 
          &#39;value&#39;: &#39;&lt;p&gt;在这普通的一天，我穿着普通的鞋...&lt;/p&gt;&#39;
        }
      ], 
      &#39;summary&#39;: &#39;&lt;p&gt;在这普通的一天，我穿着普通的鞋...&lt;/p&gt;&#39;
    }, {
      // 另外一篇文章
    }
  ], 
  &#39;bozo&#39;: 0, 
  &#39;headers&#39;: {
    &#39;Server&#39;: &#39;Tengine&#39;, 
    &#39;Content-Type&#39;: &#39;application/xml&#39;, 
    &#39;Transfer-Encoding&#39;: &#39;chunked&#39;, 
    &#39;Connection&#39;: &#39;close&#39;, 
    &#39;Vary&#39;: &#39;Accept-Encoding&#39;, 
    &#39;Strict-Transport-Security&#39;: &#39;max-age=31536000&#39;, 
    &#39;Date&#39;: &#39;Tue, 18 Aug 2020 13:37:32 GMT&#39;, 
    &#39;x-oss-request-id&#39;: &#39;5F3BD99C7DD3BB333136465D&#39;, 
    &#39;x-oss-cdn-auth&#39;: &#39;success&#39;, 
    &#39;ETag&#39;: &#39;W/&quot;7885150FF626A52F9C8E511300EDC191&quot;&#39;, 
    &#39;Last-Modified&#39;: &#39;Tue, 18 Aug 2020 04:11:35 GMT&#39;, 
    &#39;x-oss-object-type&#39;: &#39;Normal&#39;, 
    &#39;x-oss-hash-crc64ecma&#39;: &#39;904326687370716414&#39;, 
    &#39;x-oss-storage-class&#39;: &#39;Standard&#39;, 
    &#39;x-oss-server-side-encryption&#39;: &#39;AES256&#39;, 
    &#39;Content-MD5&#39;: &#39;eIUVD/YmpS+cjlETAO3BkQ==&#39;, 
    &#39;x-oss-server-time&#39;: &#39;40&#39;, 
    &#39;Via&#39;: &#39;cache36.l2cm9-5[104,0], kunlun8.cn2479[127,0]&#39;, 
    &#39;Timing-Allow-Origin&#39;: &#39;*&#39;, 
    &#39;EagleId&#39;: &#39;249c511c15977578523801838e&#39;, 
    &#39;Content-Encoding&#39;: &#39;gzip&#39;
  }, 
  &#39;etag&#39;: &#39;W/&quot;7885150FF626A52F9C8E511300EDC191&quot;&#39;, 
  &#39;updated&#39;: &#39;Tue, 18 Aug 2020 04:11:35 GMT&#39;, 
  &#39;updated_parsed&#39;: time.struct_time(tm_year=2020, tm_mon=8, tm_mday=18, tm_hour=4, tm_min=11, tm_sec=35, tm_wday=1, tm_yday=231, tm_isdst=0), 
  &#39;href&#39;: &#39;https://blog.monsterx.cn/feed.xml&#39;, 
  &#39;status&#39;: 200, 
  &#39;encoding&#39;: &#39;utf-8&#39;, 
  &#39;version&#39;: &#39;rss20&#39;, 
  &#39;namespaces&#39;: {
    &#39;dc&#39;: &#39;http://purl.org/dc/elements/1.1/&#39;, 
    &#39;content&#39;: &#39;http://purl.org/rss/1.0/modules/content/&#39;, 
    &#39;&#39;: &#39;http://www.w3.org/2005/Atom&#39;
  }
}</code></pre>
</details><br />


<p>可以看到解析出来像是 JSON 格式，而且不仅仅包含 XML 文件可见内容，HTTP Header 信息也在其中。值得注意的地方： <code>&lt;item&gt;&lt;pubDate&gt;</code> 并不是通过形如 <code>items[0].pubDate</code> 获取，而是 <code>items[0].published</code> 。根据这个结构更加灵活的运用 feedparser 吧！实现 README 自动更新最近博文并不需要这些，我给的示例足够用了。</p>
<h3 id="re-正则表达式替换">re 正则表达式替换</h3>
<p>学 re 库从 Python 官方文档开始：《<a href="https://docs.python.org/zh-cn/3/library/re.html">re --- 正则表达式操作 - Python 3 中文文档</a>》。不过最重要的还是学会写正则表达式，多写一些多搜一搜，时间久了自然就会了，我是这么想的。这里给出用于匹配 <strong>指定字符串之间所有内容且不包含指定字符串</strong> 的正则表达式。</p>
<ul>
<li><code>(?&lt;=MARK)</code> 指定以 <code>MARK</code> 开头，遇到 <code>MARK</code> 后开始匹配</li>
<li><code>(?=MARK)</code> 指定 <code>MARK</code> 结尾，遇到 <code>MARK</code> 前停止匹配</li>
<li><code>.</code> 在默认模式匹配除了换行的任意字符。re 库中如果指定了标签 <code>DOTALL</code> 则匹配包括换行符的任意字符</li>
<li><code>*</code> 对它前面的正则式匹配 0 到任意次重复，尽可能多地匹配</li>
</ul>
<pre><code class="language-python"># 拼接正则表达式并指定标签 DOTALL
# (?&lt;=(STARTMARK)).*(?=(ENDMARK))

start = &quot;&lt;!-- posts start --&gt;&quot;
end = &quot;&lt;!-- posts end --&gt;&quot;
pattern = re.compile(
    r&quot;(?&lt;=(&quot; + start + r&quot;)).*(?=(&quot; + end + r&quot;))&quot;,
    re.DOTALL,
)</code></pre>
<p><code>re.compile()</code> 将正则表达式的样式编译为一个正则表达式对象（正则对象），如果需要多次使用一个正则表达式的话，使用 <code>re.compile()</code> 保存这个正则对象以便复用，可以让程序更加高效。参数：<code>re.compile(pattern, flags=0)</code>，参考官方文档给出介绍如下：</p>
<blockquote>
<p><strong>re.sub(pattern, repl, string, count=0, flags=0)</strong> [^1] <br />
返回通过使用 <code>repl</code> 替换在 <code>string</code> 最左边非重叠出现的 <code>pattern</code> 匹配的字符串。</p>
</blockquote>
<ul>
<li><code>pattern</code> 可以是字符串或对象，在无匹配到时原样返回 <code>string</code></li>
<li><code>repl</code> 可以是字符串或函数。<code>pattern</code> 为字符串时 <code>repl</code> 中任何反斜杠转义序列都会被处理，如 <code>\n</code> 会被转换为换行符、<code>\r</code> 会被转换为回车符。ASCII 字符的未知转义符会被保留供将来使用并被视为错误。其他未知转义符例如 <code>\&amp;</code> 会保持原样。反向引用（Backreferences）例如 <code>\6</code> 将被替换为 <code>pattern</code> 所匹配到的第 6 组的子字符串</li>
<li><code>repl</code> 是字符串时，对所述的转义符和反向引用（Backreferences）中有几处特殊需要说明<ul>
<li>形如 <code>\g&lt;name&gt;</code> 用作 <code>(?P&lt;name&gt;…)</code> 语法定义的 <code>name</code> 组的匹配到的子字符串</li>
<li>形如 <code>\g&lt;number&gt;</code> 用作对应数字的组，例如 <code>\g&lt;2&gt;</code> 就是 <code>\2</code>，但它避免了同 <code>\g&lt;2&gt;0</code> 的歧义</li>
<li>形如 <code>\20</code> 会被解释为组 <code>20</code>，而不是组 <code>2</code> 后面跟随一个字符 <code>0</code></li>
<li>反向引用（Backreferences）例如 <code>\g&lt;0&gt;</code> 等同于由 <code>pattern</code> 匹配的整个子字符串</li>
</ul>
</li>
<li><code>repl</code> 是函数时，在每次非重叠出现 <code>pattern</code> 时都会被调用。这个函数只能有一个 <em>匹配对象</em> 参数，并返回替换后的字符串</li>
<li>可选参数 <code>count</code> 是要替换的最大次数，必须为非负整数。如果忽略这个参数或设置为 0，所有的匹配都会被替换</li>
<li>空匹配（Empty matches）仅在不与先前的空匹配相邻时，才被替换。所以 <code>sub(&#39;x*&#39;, &#39;-&#39;, &#39;abxd&#39;)</code> 将返回 <code>-a-b--d-</code></li>
</ul>
<p>文档太专业了，总之 <code>re.sub(pattern, repl, string)</code> 可以用 <code>repl</code> 替换掉 <code>string</code> 内所有与 <code>pattern</code> 匹配的内容，这便是最基础的用法了。使用编译后的样式 <code>pattern.sub(repl, string)</code> 效果一样。</p>
<p>写个示例：</p>
<pre><code class="language-python">import re

start = &quot;STARTMARK&quot;
end = &quot;ENDMARK&quot;
repl = &quot;text used to replace&quot;
contents = &quot;&quot;&quot;text wait STARTMARK ing for being ENDMARK replaced&quot;&quot;&quot;

pattern = re.compile(
  r&quot;(?&lt;=(&quot; + start + r&quot;)).*(?=(&quot; + end + r&quot;))&quot;,
  re.DOTALL,
)
pattern.sub(repl, contents)

print(contents)</code></pre>
<p>最终输出 <code>contents</code> 为 <code>text wait STARTMARKtext used to replaceENDMARK replaced</code>。</p>
<h3 id="python-文件读写">Python 文件读写</h3>
<p>懒得深究了，因为从之前作者的代码里找到了关于读写的:</p>
<pre><code class="language-python"># 当前文件的文件夹路径
thisdir = pathlib.Path(__file__).parent.resolve()
# .py 与 README.md 同级时获取 README 完整路径
thisfile = thisdir / &quot;README.md&quot;
# 取得 README 内容
contents = thisfile.open().read()
# 结合之前的 re 库示例实现替换
readme.open(&quot;w&quot;).write(pattern.sub(repl, contents))</code></pre>
<p>C 语言文件读写 <code>fopen()</code> 后还有 <code>fclose()</code> 的，作者的代码里没有找到 close 之类的。应该是程序结束默认关闭了吧，急于实现功能，此处没有留意。</p>
<h2 id="整理整套代码">整理整套代码</h2>
<p>以上所有学习途径自以为都交代清楚了，最后整合时用了 <code>for</code> 循环和数组的 <code>[start:end:step]</code> 分割（像数学上的区间表示法）来获取最近的固定篇数，完整实现这个「从 RSS 获取最近更新并以 Markdown 格式写入 README」的功能需要的代码篇幅很短，Python 真有趣！</p>
<pre><code class="language-python">import feedparser
import pathlib
import re

rssUrl = &quot;https://blog.monsterx.cn/feed.xml&quot;
startMark = r&quot;&lt;!-- posts start --&gt;&quot;
endMark = r&quot;&lt;!-- posts end --&gt;&quot;
NUM = 5

def update_readme(start, end, repl):
    # Splicing complete regular expressions
    pattern = re.compile(
        r&quot;(?&lt;=(&quot; + start + r&quot;)).*(?=(&quot; + end + r&quot;))&quot;,
        re.DOTALL,
    )
    # Get contents and rewrite README.md
    readme = pathlib.Path(__file__).parent.resolve() / &quot;README.md&quot;
    readme_contents = readme.open().read()
    readme.open(&quot;w&quot;).write(pattern.sub(&#39;\n&#39; + repl + &#39;\n&#39;, readme_contents))

def fetch_posts(url):
    blog = feedparser.parse(url)
    posts = blog[&#39;entries&#39;]
    markdown = &quot;\n&quot;
    # Fetch only 5 latest posts&#39; info
    # My post.published return &quot;Tue, 30 Jun 2020 00:00:00 GMT&quot;
    # So I just intercept the middle part of the character
    for post in posts[:NUM]:
        # markdown += &quot; ※ 《[&quot; + post.title + &quot;](&quot; + post.link + &quot;)》&quot; + post.published + &quot;&lt;br /&gt;\n&quot;
        markdown += &quot; ※ 《[&quot; + post.title + &quot;](&quot; + post.link + &quot;)》&quot; + post.published[5:16] + &quot;&lt;br /&gt;\n&quot;
    markdown += &quot;\n\n [Read more..](&quot; + blog[&#39;feed&#39;][&#39;link&#39;] + &quot;)\n&quot;
    return markdown

if __name__ == &quot;__main__&quot;:
    postsNew = fetch_posts(rssUrl)
    update_readme(startMark, endMark, postsNew)</code></pre>
<p>按需小小修改一下，执行 <code>python this.py</code> 即可替换指定字符串之间内容为最新的博客文章。「自动」的事情依旧交给 GitHub Actions，设置自己点 Star 触发和定时执行即可。给出我的工作流配置 <a href="https://github.com/monsterxcn/monsterxcn/blob/master/.github/workflows/new.yml">new.yml</a>，和之前打卡项目相同的原理。（看到这里的你也许有兴趣读读我之前编写这种定时工作流的文章 🤣。</p>
<p>上面的定时执行工作流也许对于像我这种更新缓慢的博客来说有点浪费，于是我又写了个从「博客」仓库执行的工作流，这样只要「博客」仓库有文章更新就会第一时间更新 README！使用前先根据《<a href="https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token">Creating a personal access token - GitHub Docs</a>》创建一个 Personal Access Token，要有写入仓库的权限。然后将生成的 Token 作为 Secrets 写入「博客」仓库。最后在「博客」仓库新建 <code>readme.yml</code>。</p>
<p>由于我的博客仓库暂时没有公开（想到稳定两周年那天再公开，整点仪式感），所以直接将仓库里的工作流贴在这里吧。只需要将自己的站点发布工作流名称、Token 在「博客」仓库中的 Secrets 名称、README 仓库地址修改到下面 L10 L22-23 即可。</p>
<p>编写参考 <a href="https://github.com/actions/checkout">@actions/checkout</a> 和《<a href="https://docs.github.com/en/actions/reference/events-that-trigger-workflows#workflow_run">Events that trigger workflows #workflow_run - GitHub Docs</a>》</p>
<details><summary><strong>从「博客」仓库更新 profile README 的工作流 readme.yml</strong></summary><br />


<pre><code class="language-yaml">name: Update README

on:
  # 直接使用 push 触发可能无法获取最新状态
  # 这里设为在发布工作流执行完毕之后触发
  # push:
  #   branches:
  #     - master
  workflow_run:
    workflows: [&quot;Deploy to OSS&quot;]      # 修改为你的站点发布工作流 name
    types: 
      - completed

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v2
        with:
          token: ${{ secrets.UPDATE_README }}   # 修改为自定义的 Secrets 名
          repository: monsterxcn/monsterxcn     # 修改为 README 仓库地址

      - name: Setup
        uses: actions/setup-python@v2
        with:
          python-version: &#39;3.x&#39;

      - name: Install
        run: pip install feedparser

      - name: Update
        run: python build_readme.py

      - name: Commit
        env:
          TZ: Asia/Shanghai
        run: |
          git config --local user.email &quot;github-actions[bot]@users.noreply.github.com&quot;
          git config --local user.name &quot;github-actions[bot]&quot;
          git add README.md
          git commit -m \
          &quot;:beers: Update from BlogRepo at \
          $(date +&quot;%Y-%m-%d %H:%M&quot;) \
          &quot; --allow-empty
          git push</code></pre>
</details><br />


<blockquote>
<p>我的 README [^2] 使用了 <a href="https://github.com/anuraghazra/github-readme-stats">@anuraghazra/github-readme-stats</a> 展示 GitHub 账号的统计信息，使用了 <a href="https://shields.io">Shields.io</a> 和 <a href="https://simpleicons.org">Simple Icons</a> 生成精致的图标。快来给自己也安排一个吧！</p>
</blockquote>
<p>[^1]: 《<a href="https://docs.python.org/zh-cn/3/library/re.html#re.sub">re --- 正则表达式操作 --- re.sub - Python 3 中文文档</a>》
[^2]: GitHub 仓库地址 <a href="https://github.com/monsterxcn/monsterxcn">@monsterxcn/monsterxcn</a></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[新起点 × 博客中文排版]]></title>
            <link>https://blog.monsterx.cn/life/new-start-with-gridsome/</link>
            <guid>https://blog.monsterx.cn/life/new-start-with-gridsome/</guid>
            <pubDate>Sat, 15 Aug 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>在这普通的一天，我穿着普通的鞋，很普通地呆在这普通的家，掏出普通的耳机，找点普通的感觉，来一首我最爱的普通音乐，踩着普通的鼓点，世界随着我旋转，这让我普通地单曲循环，跟着普通的节奏，手腕普通地抖动，这普通的一切，都变得不同……</p>
<h2 id="新的平台">新的平台</h2>
<p>博客稳定两周年之际，我正式从动态博客迁移至静态博客，如你所见这个博客正由 <a href="https://gridsome.org">Gridsome</a> 驱动着。「Gridsome 是一个免费、开源、基于 Vue.js 构建的框架，用 Gridsome 创建的网站和应用程序具有天然的速度优势」，身边用 <a href="https://hexo.io">Hexo</a> 的人似乎太多了，喜欢尝试小众作品的我选择了 Gridsome。除此之外，似乎是从给旧站点加了 Statusbot <a href="https://status.monsterx.cn">状态监控</a> 开始站内垃圾评论数量陡增，一直在用 Typecho 原生评论的我实在顶不住，评论拦截插件虽然也有，但都不太能满足我的需求，索性换个评论系统加入大家都说好的 Disqus 大家族了。</p>
<p>使用 Disqus 的痛处其一是评论数据同步，手动导入了两篇文章的数据之后发现评论区头像都无法显示，网上的解决方案似乎得购买 Disqus 商业套餐。其二是国内用户上网环境不佳便无法评论，向来冷清的本站雪上加霜，以后可能会考虑在国内服务器上继续部署 <a href="https://lab.mocurio.com/artalk.html">Artalk</a> 评论系统以供 <del>小部分人的需求</del> 自娱自乐。</p>
<p>本站的主题参考 <a href="https://blog.spencerwoo.com">@Spencer&#39;s Blog</a> 和 <a href="https://blog.jalenchuh.cn">@Jalen&#39;s Blog</a> 的仓库修改，基于 <a href="https://github.com/gridsome/gridsome-starter-blog">@gridsome/gridsome-starter-blog</a>。静态博客可以自由部署在很多地方，目前这个博客通过 GitHub Actions 自动构建静态文件发布到私有仓库的分支和阿里云 OSS，配合阿里云全站加速供中国境内访问，同时部署到 Cloudflare Workers Sites 供境外访问。以前将域名的境内境外解析拆分，是考虑国外可能会有人访问，现在想明白了，这其实是为了国内日常科学上网的同志们。就算是「人在纽约」访问本站应该也能获取稍快的体验。</p>
<h2 id="文章排版">文章排版</h2>
<p>格式工整的文章让人阅读的欲望更强烈。参照众多中文博客排版、GitHub 热门项目文档排版、GitHub 仓库 <a href="https://github.com/sparanoid/chinese-copywriting-guidelines">@sparanoid/chinese-copywriting-guidelines</a> 以及我的个人偏好，将本博客的 Markdown 文件书写规则做一点说明，有冲突时优先考虑下文的规则。</p>
<ul>
<li>标点符号<ul>
<li>中文内容不掺杂半角标点符号，英文内容不掺杂全角标点符号</li>
<li>中文内容使用全角直角引号代替全角双引号</li>
<li>数字内容使用半角字符</li>
<li>不使用重复的标点符号，「...」除外</li>
<li>内容必须以标点符号结尾，表格、列表、代码除外</li>
</ul>
</li>
<li>空格<ul>
<li>中英文之间留空格，（按照官方格式书写）</li>
<li>中文与数字、数字与单位（「°」「℃」「%」等除外）之间留空格</li>
<li>全角标点符号前后不留空格</li>
<li>省略号「……」后留一个空格</li>
</ul>
</li>
<li>名词<ul>
<li>「豆瓣FM」等同时包含中英文的产品名词按照官方格式书写</li>
<li>专有名词使用官方格式的大小写和缩写</li>
</ul>
</li>
<li>Markdown<ul>
<li>Markdown 语法优先于 HTML 标签</li>
<li>Markdown 标题从 <code>##</code> 开始，按内容相关度分段</li>
<li>Markdown 语法与前后正文内容之间留一个空格，全角标点符号除外</li>
</ul>
</li>
<li>其他<ul>
<li>指示流程的内容按「Step A -&gt; Step B -&gt; Step C」格式书写</li>
<li>指示代码行号的内容按「LNUM [-ENDNUM]」格式书写</li>
<li>引用拥有个人主页、博客或 GitHub 账号的人员名称按「@NICKNAME」格式书写</li>
<li>引用 GitHub 的仓库名称按「@USER/REPO」格式书写</li>
<li>引用文献的名称按「原标题 - 来源」格式书写并将链接包含在全角书名号之内</li>
<li>段落中阐述代码用到的「变量名称」「函数名称」等按行内代码块格式书写</li>
<li>段落中非阐述代码用到的且需要强调的内容使用直角引号包围</li>
<li>段落中文件名、文件路径、文件名后缀等内容按行内代码块格式书写</li>
<li>文章正文内各级标题要意义明确、格式一致、保持简洁，不多于两层标题嵌套</li>
<li>文章中表示个人想法、从别处摘抄的内容按照引用格式书写</li>
<li>文章直接引用到正文的内容不符合本站规则的地方需要进行适当调整</li>
<li>文章中引用的、可能存在争议的内容在脚注中进行说明</li>
</ul>
</li>
</ul>
<p>除去这些规定，在文章的分类和标签上我也相较原来的 Typecho 博客做了些精简。分类目前想法是只保留 <a href="https://blog.monsterx.cn/category/life">life</a> <a href="https://blog.monsterx.cn/category/code">code</a> <a href="https://blog.monsterx.cn/category/tech">tech</a> 三类，分别用来保留筛选后关于「记录生活的手帐、站点杂务」「写代码的探索和思考」「学习某些技术、使用轮子的日志」的内容。每篇文章的标签保持精简，写完整篇文章后提取两到三个关键词作为标签。</p>
<p>做完这些剩下的就是提升自身水平了……</p>
<h2 id="keep-moving">Keep moving...</h2>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[从零开始的追番生活]]></title>
            <link>https://blog.monsterx.cn/tech/auto-download-bangumi-with-aria2-rss/</link>
            <guid>https://blog.monsterx.cn/tech/auto-download-bangumi-with-aria2-rss/</guid>
            <pubDate>Tue, 28 Jul 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>最近觉得为了偶尔看看电影动漫而续费腾讯视频会员太吃亏了，一个月四集的《斗罗大陆》水得不行啊喂！哔哩哔哩大会员也是如此，有的时候我在这头，想看的番剧在那头，每次都要科学上网才能解锁，属实费劲。</p>
<p>想了想自己闲置的服务器和最近开通的 Microsoft 365 E5 开发者订阅，我决定自己动手，部署一套更省钱的追番流程。最初是这样一套笨笨的追番流程：「bangumi.moe 等种子站找资源 -&gt; 服务器 Aria2 下载 -&gt; Rclone + Aria2 联动将内容转移到云盘 -&gt; 云盘网页下载」。但是这样一来科学上网工具的流量开销比较大，而且也完全称不上自动。后来我发现 Windows 系统打开 OneDrive 文件夹同步就可以免去手动登录网页下载，于是我从之前的 Google Drive 迁移到 OneDrive，这样一来流程的后两步就合并了。如何让前两步合并呢？一番搜索之后我找到了 FlexGet 这个 Python 编写的工具，众多插件使得 FlexGet 在 RSS 订阅下载上大放异彩。本文便记录这一部署过程。</p>
<h2 id="rclone">Rclone</h2>
<p>Rclone 用于网盘挂载，从 <a href="https://rclone.org/downloads/">官方</a> 下载安装，按照命令行提示输入后得到配置文件 <code>rclone.conf</code>（后续使用），路径一般为 <code>~/.config/rclone/rclone.conf</code>。</p>
<p>注意使用自己的 Secret ID &amp; Key，据说能极大的提高文件传输速率。公用的 API 想想就知道肯定比不过自建。参考文档《<a href="https://rclone.org/drive/#making-your-own-client-id">GoogleDrive: Making your own client_id - rclone.org</a>》《<a href="https://rclone.org/onedrive/#getting-your-own-client-id-and-key">OneDrive: Getting your own Client ID and Key - rclone.org</a>》创建即可。</p>
<p>Rclone 挂载 OneDrive 时需要在运行图形界面的系统上完成。Linux 服务器由于一般不带图形界面，所以需要配合本地机器：在 Windows 中下载 Rclone 相应版本文件，Power Shell 进入解压后的文件夹中键入下面命令后复制 <code>Paste the following into your remote machine ---&gt;</code> 和 <code>&lt;---End paste</code> 之间的 <code>SECRET_TOKEN</code> 到远程服务器命令行中。</p>
<pre><code class="language-powershell">.\rclone authorize &quot;onedrive&quot; &quot;Client_ID&quot; &quot;Client_secret&quot;</code></pre>
<p>OneDrive 更详细挂载过程可参考文章《<a href="https://p3terx.com/archives/rclone-connect-onedrive-with-selfbuilt-api.html">Rclone 进阶使用教程 - 自建私有 API 挂载 OneDrive - P3TERX</a>》。<strong>后面均使用 OneDrive 部署</strong>。</p>
<h2 id="aria2">Aria2</h2>
<p>Aria2 是一个强大的下载工具，这里使用 Docker 部署 Aria2 后端服务和 AriaNG 前端页面。参考文章《<a href="https://p3terx.com/archives/docker-aria2-pro.html">Aria2 Pro - 更好用的 Aria2 Docker 容器镜像 - P3TERX</a>》。</p>
<pre><code class="language-bash"># 建立 Docker 映射文件夹
mkdir /data /data/ariapro /data/ariapro/config /data/ariapro/downloads

# 复制 Rclone 配置文件
cp ~/.config/rclone/rclone.conf /data/ariapro/config/rclone.conf

# 部署 p3terx/aria2-pro 镜像
# 修改 &lt;TOKEN&gt; 为自定字符串
# 若支持 IPv6 则开启 IPV6_MODE=enable 否则需要关闭
docker run -d \
  --name ariapro \
  --restart unless-stopped \
  --log-opt max-size=1m \
  --network host \
  -e PUID=$UID \
  -e PGID=$GID \
  -e RPC_SECRET=&lt;TOKEN&gt; \
  -e RPC_PORT=6800 \
  -e LISTEN_PORT=6888 \
  -e IPV6_MODE=enable \
  -e SPECIAL_MODE=rclone \
  -v /data/ariapro/config:/config \
  -v /data/ariapro/downloads:/downloads \
  p3terx/aria2-pro

# 部署 p3terx/ariang 镜像
docker run -d \
  --name ariang \
  --restart unless-stopped \
  --log-opt max-size=1m \
  -p 6880:6880 \
  p3terx/ariang

# 配置 rclone 自动上传
# 根据实际修改网盘名称 drive-name 和网盘路径 drive-dir
nano /data/ariapro/config/script.conf
# 修改下载完成后执行的命令 on-download-complete 为 /root/.aria2c/upload.sh
nano /data/ariapro/config/aria2.conf

# 重启 Aria2 容器
docker restart ariapro</code></pre>
<h2 id="nginx">Nginx</h2>
<p>由于使用 IP 登录不太方便，所以继续部署 Nginx 服务反向代理 RPC 端口、绑定自己的域名。简便起见，直接使用 Ubuntu 仓库中的 nginx 包。如果服务器中已安装 Nginx，则直接新建配置文件。</p>
<pre><code class="language-bash">apt install -y nginx</code></pre>
<p>安装好后 Nginx 配置文件位于 <code>/etc/nginx</code>，于 <code>/etc/nginx/conf.d</code> 文件夹下新建 <code>.conf</code> 文件：</p>
<details><summary><strong>Nginx 配置文件</strong></summary><br />


<pre><code class="language-nginx">server {
  listen [::]:80;                       # 若支持 IPv6 则启用
  listen 80;
  listen [::]:443 ssl http2;            # 若支持 IPv6 则启用
  listen 443 ssl http2;
  ssl_certificate /path/to/.crt;        # .crt 证书文件路径
  ssl_certificate_key /path/to/.key;    # .key 证书文件路径
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;
  ssl_ciphers TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-128-CCM-8-SHA256:TLS13-AES-128-CCM-SHA256:EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;
  ssl_prefer_server_ciphers on;
  ssl_session_timeout 10m;
  ssl_session_cache builtin:1000 shared:SSL:10m;
  ssl_buffer_size 1400;
  add_header Strict-Transport-Security max-age=15768000;
  server_name www.example.com;          # 域名
  access_log off;
  if ($ssl_protocol = &quot;&quot;) { return 301 https://$host$request_uri; }

  location / {
    proxy_redirect off;
    proxy_pass http://localhost:6880;     # 修改为 ariang 端口
    proxy_set_header  Host                $http_host;
    proxy_set_header  X-Real-IP           $remote_addr;
    proxy_set_header  X-Forwarded-Ssl     on;
    proxy_set_header  X-Forwarded-For     $proxy_add_x_forwarded_for;
    proxy_set_header  X-Forwarded-Proto   $scheme;
    proxy_set_header  X-Frame-Options     SAMEORIGIN;
    client_max_body_size        100m;
    client_body_buffer_size     128k;
    proxy_buffer_size           4k;
    proxy_buffers               4 32k;
    proxy_busy_buffers_size     64k;
    proxy_temp_file_write_size  64k;
  }
  location ^~ /jsonrpc {
    proxy_http_version 1.1;
    add_header Front-End-Https on;
    proxy_set_header Connection &quot;&quot;;
    proxy_set_header Host $http_host;
    proxy_set_header X-NginX-Proxy true;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    # 修改为 p3terx/aria2-pro 容器 RPC_PORT
    proxy_pass http://localhost:6800/jsonrpc;
    proxy_pass_header X-Transmission-Session-Id;
  }
  # 多个 aria2 后端示例
  # location ^~ /googlejsonrpc {                # 修改
  #   proxy_http_version 1.1;
  #   add_header Front-End-Https on;
  #   proxy_set_header Connection &quot;&quot;;
  #   proxy_set_header Host $http_host;
  #   proxy_set_header X-NginX-Proxy true;
  #   proxy_set_header X-Real-IP $remote_addr;
  #   proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
  #   proxy_pass http://localhost:6802/jsonrpc; # 修改
  #   proxy_pass_header X-Transmission-Session-Id;
  # }
}</code></pre>
</details><br />


<p>修改上方例子中的域名、端口即可。多个 Aria2 RPC 端口时可以参考注释掉的部分。最后重启 Nginx。</p>
<pre><code class="language-bash">service nginx restart
# nginx -s reload</code></pre>
<h2 id="rss">RSS</h2>
<p>部署 FlexGet 之前当然是先找支持 RSS 订阅的站点！目前我个人觉得萌番组的体验还不错！<a href="https://bangumi.moe">萌番组官网</a> / <a href="https://bangumi.moe/lite">萌番组 Lite 版官网</a> / <a href="https://bgm.ptr.moe">萌番组 Material Design 版</a>。点击搜索图标添加 Tags 搜索后 RSS 图标链接地址即为可用订阅地址，切换标题搜索同理。</p>
<p>比如 添加标签「Lilith-Raws」「租借女友」「1080p」和搜索标题「Lilith 賢者時間 1080p」分别可以得到这两种 RSS 订阅地址：</p>
<pre><code>https://bangumi.moe/rss/tags/5d8b3245306f1a0007bd7aca+548ee2ce4ab7379536f56358+5efffb4f3d656e43622cacc9
https://bangumi.moe/rss/search/Lilith%20%E8%B3%A2%E8%80%85%E6%99%82%E9%96%93%201080p</code></pre><p>除了 bangumi.moe 之外还有很多平台，部分资源相同，罗列一些包括但不限于二次元的资源站：</p>
<ul>
<li>BT RSS 订阅<ul>
<li><a href="https://share.dmhy.org">動漫花園資源網</a> 动漫、日剧、游戏、特摄等</li>
<li><a href="https://acg.rip">ACG.RIP</a> 动画、日剧、综艺、音乐等</li>
<li><a href="https://bt.xfsub.org">旋风动漫分享站</a> 漫画</li>
<li><a href="https://nyaa.si">Nyaa</a> 侧重于东亚（中日韩）多媒体资源，被日本政府确定为主要的数字盗版网站</li>
<li><a href="https://yts.mx">YIFY</a> 以 BitTorrent 分发大量免费下载的电影而闻名，国内很多电影资源源头</li>
<li><a href="https://eztv.io">EZTV</a> 国外电视节目等，「TV Torrents Online Series Download」</li>
<li><a href="https://thepiratebay10.org/">The Pirate Bay 10</a> 据称是「the galaxy&#39;s most resilient BitTorrent site」</li>
<li><a href="http://f.cili001.com/home.html">MAG 磁力站</a> 侧重影视剧集，可以搜人人影视专用链接</li>
</ul>
</li>
<li>字幕<ul>
<li><a href="https://bbs.vcb-s.com/forum-37-1.html">VCB-S 分享论坛</a> ACG 字幕分享</li>
<li><a href="https://subhd.tv/">SubHD.tv</a> 资源+字幕站，找字幕体验非常好</li>
<li><a href="http://www.zmtiantang.cc">字幕天堂</a></li>
</ul>
</li>
<li>漫画<ul>
<li><a href="http://www.animetox.com">Animex 动漫社</a> 最近找进击的巨人漫画发现的</li>
<li><a href="http://mangabz.com">Māngabz</a> 在线漫画阅读</li>
<li><a href="https://www.dmzj.com">动漫之家</a></li>
<li><a href="https://www.omyschool.com">木马漫画</a></li>
</ul>
</li>
</ul>
<h2 id="flexget">FlexGet</h2>
<p>以上部分搭建了基础的下载环境，接下来利用 FlexGet 实现 Aria2 的 RSS 订阅下载。</p>
<blockquote>
<p>FlexGet is a multipurpose automation tool for all of your media <br />
Support for torrents, nzbs, podcasts, comics, TV, movies, RSS, HTML, CSV, and more.  [^1]</p>
</blockquote>
<p>由于是 Python 编写，需要先安装 python3 pip3 包。</p>
<pre><code class="language-bash">apt install python3 python3-pip
pip3 install --upgrade pip setuptools
pip3 install flexget</code></pre>
<p>安装完成后新建 FlexGet 配置文件夹并编写配置文件。</p>
<pre><code class="language-bash">mkdir -p ~/.config/flexget
nano ~/.config/flexget/config.yml</code></pre>
<details><summary><strong>FlexGet 配置文件</strong></summary><br />


<pre><code class="language-yaml">schedules:
  - tasks: &quot;*&quot;
    schedule:
      hour: &quot;*/2&quot;

tasks:
  KanojoOkarishimasu:
    rss: https://bangumi.moe/rss/tags/5d8b3245306f1a0007bd7aca+548ee2ce4ab7379536f56358+5efffb4f3d656e43622cacc9
    accept_all: yes
    aria2:
      server: localhost
      port: 6800
      secret: &lt;TOKEN&gt;
      path: /租借女友/
  YahariOrenoSeishunLovecomewaMachigatteIruKan:
    rss: https://bangumi.moe/rss/tags/5d8b3245306f1a0007bd7aca+548ee2ce4ab7379536f56358+5e822875657e22f4195cc78c
    accept_all: yes
    aria2:
      server: localhost
      port: 6800
      secret: &lt;TOKEN&gt;
      path: /我的青春恋爱物语果然有问题.完/
  DouLuoDaLu:
    rss: https://bangumi.moe/rss/search/GM-Team%20%E6%96%97%E7%BD%97%E5%A4%A7%E9%99%86%201080p
    accept_all: yes
    aria2:
      server: localhost
      port: 6800
      secret: &lt;TOKEN&gt;
      path: /斗罗大陆/
  Japan4KAnimeYTSMX:
    rss: https://yts.mx/rss/0/2160p/animation/0/ja
    accept_all: yes
    aria2:
      server: localhost
      port: 6800
      secret: &lt;TOKEN&gt;
      path: /YTS.MX.Japan4KAnime/</code></pre>
</details><br />


<p>注意修改 Aria2 后端端口和 Secret。保存后手动运行测试一次，选一种模式设置定时任务，查看状态。</p>
<pre><code class="language-bash">flexget --test execute

flexget status

# Daemon 模式定时任务
#  -d                     后台运行
#  --autoreload-config    执行前重新载入配置文件
@reboot /usr/local/bin/flexget daemon start -d --autoreload-config

# Crontab 模式定时任务
# 删掉前面配置文件中的 scheduler 块配置
# 使用偏好的编辑器进入，添加一行
crontab -e
*/30 * * * * /usr/local/bin/flexget --cron execute</code></pre>
<p>关于定时任务，上方示例中开头 L1-4 的配置使用了 scheduler 插件，只有在 Daemon 模式下才可用。使用 crontab 定时任务不需要该配置。</p>
<h2 id="local">Local</h2>
<p>最后一步，在本地登录 OneDrive 账号设置同步文件夹。右键将本地文件夹标记为「始终在此设备上保留」即可，当云端存入新的文件时本地就会自动下载同步。删除本地文件夹时，默认会将 OneDrive 云端文件一同删除，只删除本地需要右键选择「释放空间」。</p>
<p>白嫖的开发者订阅 OneDrive 服务器位于境外，从服务器 Rclone 上传文件速度很好，但是有人说本地下载速度太慢，这无法避免。如果使用世纪互联版 OneDrive 本地下载速度肯定会好很多，但服务器上传想必会慢些，自行权衡吧。我使用几周以来尚且满意，睡一觉起来想要看的东西就会自己出现在那里，宅の生活质量提升了，人也变得精神了呢！</p>
<h2 id="end">End</h2>
<p>关于部署上面流程的服务器强烈推荐使用国外的，国内的服务器网络带宽、Docker 部署、BT 下载环境一言难尽。我用的是 Digital Ocean 新加坡服务器，体验良好。如果就看看新番、一集一集下硬盘需求不是很高，20-40 GB 应该就可以了，要拿来正儿八经下东西硬盘还得越大越好的，这几天下的紫罗兰 4K 版全集就有 43 GB 了。本想着部署「省钱」的追番流程，结果下载服务器一个月就花了几十刀，害，钱还是得花！</p>
<p>另外安利一个微软收购的文件转移工具：<a href="https://mover.io/">Mover</a> 安全、强大、快速的文件转移工具，Microsoft 365 用户福音，可以实现 Box，Dropbox，Google，Amazon，Office 365（原 Microsoft 365） 向 Microsoft 365 转移文件，并且支持定时任务！</p>
<ul>
<li>现成的 OneDrive 文件：<a href="https://monstx-my.sharepoint.com/:f:/g/personal/storage_tingle_dev/EkM5OfD1nrZBr_214_JmLtgBNz05mQMNqIEFsZOb9FIMBg%EF%BC%9Fe=EM2tX5">Anime</a> / <a href="https://monstx-my.sharepoint.com/:f:/g/personal/storage_tingle_dev/EozDcDrM7edEpnZmeL1dDQABZg0xhZNUvnj7IvBlHKM6YA%EF%BC%9Fe=M944ih">Movies</a> / <a href="https://monstx-my.sharepoint.com/:f:/g/personal/storage_tingle_dev/ErcXo0q92thGqrbkpzurmI8BOXwGMJgP0AiwB5lZa_cvuw%EF%BC%9Fe=SM2cWU">Series</a></li>
<li>部分境外服务器可能禁止 BT 服务，选购前请仔细阅读用户条例</li>
<li>有条件的话下载完毕后请做种一段时间</li>
</ul>
<center><span style="font-size:30px">微软赛高！</span></center>


<p>[^1]: <a href="https://flexget.com/">FlexGet Official website</a></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[照葫芦画瓢 · 编写 Actions 打卡工作流]]></title>
            <link>https://blog.monsterx.cn/tech/modified-github-actions-4-heu-checkin/</link>
            <guid>https://blog.monsterx.cn/tech/modified-github-actions-4-heu-checkin/</guid>
            <pubDate>Tue, 30 Jun 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>昨天逛博客看到了使用 GitHub Actions 定时调用 Microsoft 365 E5 API 以帮助续订的文章，我转念一想这是不是也可以用来跑定时任务打卡呢？说干就干我开了一个小的坑：用 GitHub Actions 跑之前写的 Python 打卡脚本。无意薅羊毛，只是希望通过一点学习将自己的想法实现。</p>
<h2 id="照葫芦环节">照葫芦环节</h2>
<p>参考项目 <a href="https://github.com/wangziyingwen/AutoApiSecret">@wangziyingwen/AutoApiSecret</a> 的 <a href="https://github.com/wangziyingwen/AutoApiSecret/blob/master/.github/workflows/autoapi.yml">autoapi.yml</a>，搞懂了这一流程：</p>
<ol>
<li>将私密信息存于仓库 Secrets，以 <code>name=value</code> 的赋值语句格式定义</li>
<li>将 Secrets 内容写入脚本复制来的临时文件</li>
<li>执行填入了 Serects 的临时文件</li>
<li>删除所有临时文件并提交历史记录</li>
</ol>
<p>「定时」这一特性是 GitHub Actions 提供的，在触发条件中定义 <code>on.schedule.cron</code> 即可！呐噜吼多！将 Secrets 写入文件是通过 Linux 命令 <code>sed</code> 实现的，比如使用 <code>sed -i &#39;10 r tmp.txt&#39; tmp.py</code> 可以将 <code>tmp.txt</code> 的内容写入了 <code>tmp.py</code> 的指定行 <code>10</code> 的下一行。对 Linux 命令的认知水平停留在 <code>rm -rf</code> 的我大吃一惊，呀，又学到了新知识！</p>
<h2 id="画瓢环节">画瓢环节</h2>
<p>此刻，白嫖是第一生产力。了解了这样的流程部署自己的自动打卡（让 GitHub 定时执行 <code>python checkin.py</code>）就不是什么难事了。</p>
<details><summary><strong>照葫芦画瓢 python.yml 第一版</strong></summary><br />


<pre><code class="language-yaml">name: Auto Checkin

on: 
  release:
    types: [published]
  # Coordinated Universal Time (UTC)
  schedule:
    - cron: &#39;0 0 * * *&#39;           # 定时任务实现方式
  watch:
    types: [started]

jobs:
  build:
    runs-on: ubuntu-latest
    if: github.event.repository.owner.id == github.event.sender.id  # 仅自己点的 star 触发
    steps:
      - name: Checkout
        uses: actions/checkout@master

      - name: Python Setup
        uses: actions/setup-python@v1
        with:
          python-version: 3.8

      - name: Pip Cache             # 按照官方仓库 @actions/cache 添加
        uses: actions/cache@v2
        with:
          path: ~/.cache/pip        # Ubuntu 的缓存位置，不同系统不同位置需要修改
          key: ${{ runner.os }}-pip-${{ hashFiles(&#39;**/requirements.txt&#39;) }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Addons Install        # 安装脚本必须组件 lxml requests
        run: pip install lxml requests

      - name: Secrets Get           # 获取 Secrets
        env: 
          SECRET_ID: ${{ secrets.SECRET_ID }}
          SECRET_PASS: ${{ secrets.SECRET_PASS }}
          SECRET_BOUND: ${{ secrets.SECRET_BOUND }}
          SECRET_DATA: ${{ secrets.SECRET_DATA }}
        # 先复制一个临时文件，然后写入 Secrets 到文本，再将其写入临时脚本文件指定行
        run: | 
          cp checkin.py action.py
          echo $SECRET_ID &gt; action-id.txt
          echo $SECRET_PASS &gt; action-pass.txt
          echo $SECRET_BOUND &gt; action-bound.txt
          echo $SECRET_DATA &gt; action-data.txt
          sed -i &#39;19 r action-id.txt&#39; action.py
          sed -i &#39;20 r action-pass.txt&#39; action.py
          sed -i &#39;21 r action-bound.txt&#39; action.py
          sed -i &#39;22 r action-data.txt&#39; action.py

      - name: Checkin Action
        env:
          TZ: Asia/Shanghai         # 设定时区为北京时间
        # 工作流过程中新建 log 文件夹存放待会发布到另外一个分支的内容
        run: | 
          mkdir log
          echo `date +&quot;%Y-%m-%d %H:%M:%S %A&quot;` &gt;&gt; log/time.log
          python action.py &gt;&gt; log/time.log

      - name: Secrets Delete        # 删除临时文件
        run: rm -f action*

      - name: Deploy Log            # 发布 log 文件夹下的记录文件到 log 分支
        uses: docker://peaceiris/gh-pages:v2
        env:
          TZ: Asia/Shanghai
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PUBLISH_BRANCH: log
          PUBLISH_DIR: ./log
        with:
          emptyCommits: false</code></pre>
</details><br />


<p>第一版的工作流程看起来有点臃肿，不过管他呢，能用。</p>
<h2 id="润色">润色</h2>
<p>写完第一份工作流文件之后，我开心地将文件提交到了 GitHub 仓库，又煞有介事地写了份文档。但是坐下来反复看自己的代码之后，我越发觉得这过于粗糙。在博客的文章收到了大佬的指导，于是我有了新的思路并开始不断地给自己的代码「润色」。</p>
<h3 id="round-1">Round 1</h3>
<p>简单地实现定时任务似乎并不值得记录，于是我顺便给这个工作流引入了 pip 模块缓存、发布日志文件到分支这两个小功能，算是补上了之前折腾工作流学到的。</p>
<ul>
<li><p><strong>pip 模块缓存</strong></p>
<p>这是从苏卡大大《<a href="https://blog.skk.moe/post/deploy-blog-to-cf-workers-site">将 Hexo 部署到 Cloudflare Workers Site 上的趟坑记录 - Sukka&#39;s Blog</a>》中学到的。Node.js 项目构建时需要的依赖挺多，没有缓存的话每次 GitHub Action 得跑很长分钟，于是他给出了缓存 node_modules 的办法： <code>uses: actions/cache@v2</code> ，通过检查缓存特征 Key 是否存在，比如 Node.js 就检测是否存在 <code>package-lock.json</code> 文件，进而处理缓存。</p>
<p>GitHub Actions 使用这一特性其实很简单，只要按照 <a href="https://github.com/actions/cache">@actions/cache</a> 中需要缓存的类型确定好监测的特定路径和文件，编写类似上方 L26-31 的步骤在安装依赖前即可。之前尝试是能将用于构建并发布站点的 2 mins 工作流优化到 1 min 多，提升还是蛮大的。</p>
<p>在这个项目中缓存 pip 模块需要做的就是照葫芦画瓢检查 <code>~/.cache/pip</code> 目录下 <code>requirements.txt</code> 文件。</p>
</li>
<li><p><strong>发布 log 记录文件到分支</strong></p>
<p>这是从 Typecho-Theme-VOID 二次开发过程中学到的。它的 Actions 将编译好的文件存放在 build 文件夹然后发布到 nightly 分支。仅需在 workflows 中给 <code>uses: docker://peaceiris/gh-pages:v2</code> 添加两个环境变量 <code>PUBLISH_BRANCH</code> 和 <code>PUBLISH_DIR</code> 即可，v3 版本这一配置从 <code>env</code> 改为了 <code>with</code> 字段，具体可以看 <a href="https://github.com/peaceiris/actions-gh-pages">@peaceiris/actions-gh-pages</a>。</p>
</li>
<li><p><strong>邮件</strong></p>
<p>启用 GitHub Actions 后我将 Python 中的 SMTP 配置删除了，这原本是用来在服务器部署时完成任务后发送提醒的。我想只要开启 GitHub 工作流的运行提醒就好啦，后来意识到虽然 GitHub Actions 自身有邮件提醒，但它提醒的是工作流执行状况，并不能等价于打卡脚本的执行状态。这一点还有待优化。毕竟配置起来如果像上面一样一条一条添加 Secrets 的话就太繁琐了。</p>
</li>
<li><p><strong>微信提醒</strong></p>
<p>由于 GitHub Actions 部署邮件提醒不方便，我找到了微信提醒的工具 Server 酱，在 Python 中使用 requests 库发送请求即可触发微信提醒，结合程序执行结果可以更加完美的推送打卡提醒；Ruby 不会写，我就直接从 Actions 执行时由命令行 <code>curl</code> 发送请求了，这些代码十分粗糙，放在了仓库 personal 分支下。</p>
</li>
</ul>
<h3 id="round-2">Round 2</h3>
<p>也许看官早就想说了：为什么引用 Secrets 而已，又是设置环境变量、又是将环境变量 <code>echo</code> 到 <code>.txt</code> 文件、又是将 <code>.txt</code> <code>sed</code> 写入 <code>.py</code> 的，不能简单点吗？确实，在朋友 <a href="https://xyenon.bid">@XYenon</a> 的指导下我得知 Python 可以通过 <code>os.environ</code> 读取环境变量，所以简单的办法来了，将 Python 脚本中原来的赋值改写成下面的格式直接读环境变量</p>
<pre><code class="language-python">import os

myid = os.environ [&#39;SECRET_ID&#39;]</code></pre>
<p>直接读入环境变量 <code>SECRET_ID</code> 的值并赋给 <code>myid</code> 。如此一来，上面 Secrets Get、Checkin Action、Secrets Delete 三步合并为一步：</p>
<pre><code class="language-yaml">- name: Action Execute
  env:
    TZ: Asia/Shanghai
    SECRET_ID: ${{ secrets.SECRET_ID }}
    SECRET_PASS: ${{ secrets.SECRET_PASS }}
    SECRET_BOUND: ${{ secrets.SECRET_BOUND }}
    SECRET_DATA: ${{ secrets.SECRET_DATA }}
  run: python checkin.py | tee -a checkin-python.log</code></pre>
<p>心情顿时舒畅了不少！</p>
<h3 id="round-3">Round 3</h3>
<p>上次那篇关于调试 Python 打卡的《<a href="https://blog.monsterx.cn/code/heu-auto-checkin-covid19/">Mark 并调试 HEU 自动打卡代码</a>》下 <a href="https://xyenon.bid">@XYenon</a> 给出了仅需用户名和密码的 Ruby 版本 <a href="https://gist.github.com/XYenon/79317d63e7f769e5bdff5b595d709b65">@XYenon/checkin.rb</a>。</p>
<p>代码仅 60 行，第一次看完我觉得很赞，看起来只要脚本代替人执行「确认信息 -&gt; 提交表单」两步就完事了。现有的 Python 打卡每次都将事先定义的表单数据提交一遍，不考虑打卡系统中表单在服务器的缓存。如果表单数据在服务器上一直都有缓存，那部署这个 Ruby 版本我觉得似乎会更好，毕竟仓库里可以少写两个 Secrets。</p>
<blockquote>
<p>与 Python 类似，Ruby 也可以在代码中使用 <code>ENV[&#39;SECRET_ID&#39;]</code> 这样的语句直接获取环境变量。</p>
</blockquote>
<p>实际调试的时候，我发现这看起来简单的代码部署起来也不容易…… Ruby 使用 webdrivers 库来在终端驱动一个 headless Chrome 浏览器，然后执行动作。抛开因为不熟悉 Ruby + webdrivers 这套环境使我在 GitHub Actions 工作流写法上花的时间，这个脚本跑起来效率也比较低，Python 直白地提交表单整个工作流程需要 30 秒左右，而 Ruby 模拟 Chrome 操作花了三分钟多。是为了更快的 workflow 选择 Python 打卡呢？还是为了更快的部署选择 Ruby 打卡呢？</p>
<p>经过多方搜索我使用了这样的 GitHub Actions 环境跑 Ruby + Watir + webdrivers 代码，不知道有没有更好的方式，贴在这里供大家参考：</p>
<pre><code class="language-yaml">jobs:
  build:
    runs-on: ubuntu-latest
    # 运行 headless chrome 的服务
    services:
      hub:
        image: selenium/hub:3.141.59-gold
        env:
          SELENIUM_HUB_HOST: localhost
      chrome:
        image: selenium/node-chrome:3.141.59-gold
        env:
          HUB_HOST: localhost
          HUB_PORT: 9515

    if: github.event.repository.owner.id == github.event.sender.id
    steps:
      - name: Checkout
        uses: actions/checkout@master

      - name: Ruby Setup
        uses: actions/setup-ruby@v1
        with:
          ruby-version: 2.5.x

      - name: Addons Install
        run: gem install watir webdrivers

      - name: Action Execute
        env:
          TZ: Asia/Shanghai
          LANG: zh_CN.UTF-8
          SECRET_ID: ${{ secrets.SECRET_ID }}
          SECRET_PASS: ${{ secrets.SECRET_PASS }}
        run: ruby checkin.rb | tee -a checkin-ruby.log</code></pre>
<blockquote>
<p>也许 Ruby 版本的打卡程序更适合写成 JavaScript 用户脚本交给浏览器插件执行。</p>
</blockquote>
<h2 id="结语">结语</h2>
<p>GitHub 仓库地址 <a href="https://github.com/monsterxcn/HEU-Checkin-COVID-19">@monsterxcn/HEU-Checkin-COVID-19</a>。如果仓库说明仍未找到你需要的部署过程，可以参考以下我的另外一篇文章《<a href="https://blog.monsterx.cn/code/heu-auto-checkin-covid19/">Mark 并调试 HEU 自动打卡代码</a>》</p>
<p>我原以为在 GitHub Actions 中实现定时任务要很复杂的配置，毕竟每次工作流都是相当于在一个全新的服务器上执行。现在发现原来定时任务只需要在工作流的触发事件中写入 <code>schedule</code> 即可。在查找文档时我发现这点在官方文档中有详细说明，害，都是不会看文档惹的祸。</p>
<p>榆木脑袋的我在看到别人的代码之前总是从没想过可以这样实现。比如：将私密信息以赋值语句形式写入仓库设置，执行 GitHub Actions 时将赋值语句插进文件头部继续执行。甚是高明（虽然到后面我发现这也挺笨的）。剖析了我的不足之处，浅层来看最重要的两点估计就是：</p>
<ul>
<li>我对仓库 Secrets 设置的认识是死板的，我一直将其当作 GitHub Actions 执行时传递普通变量值的纽带，仅此而已</li>
<li>不熟悉 Linux命令，虽然日常 Copy 到命令行的 Linux 命令中也有用到过 <code>sed</code>，但我并没有积极的学习</li>
</ul>
<p>深层次的原因嘛，大概是怠惰吧！</p>
<p>GitHub Actions 妙用多多，之前关注过一个博客 <a href="https://p3terx.com/">@P3TERX ZONE</a> 里写了挺多关于 GitHub Actions 的文章，有时间的话要去学习学习！</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[手帐 · 常]]></title>
            <link>https://blog.monsterx.cn/life/daily-impermanence/</link>
            <guid>https://blog.monsterx.cn/life/daily-impermanence/</guid>
            <pubDate>Mon, 18 May 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>最近的日子过得忙碌，五味杂陈。这种状态持续了多久呢……</p>
<h2 id="生活">生活</h2>
<p>大概疫情开始后我的生活就变了吧，刚开始时是铺天盖地的谣言与辟谣，以及每日新增的新闻，我想：像我这种从不门、连屋子都懒得出去的人来说唯一能让我动弹的只有快递和外卖，而现在只剩快递。心里默默计划的返校从 4 月拖到 5 月，眼下看来还要继续拖到 6 月，而原本计划返校再做的一些事不得不在家里完成，比如补考。嗯，在家学习的感觉不算太差也不算太好，前半句是因为我不再需要从众，没必要做样子给谁看；后半句则是因为在家也免不了走神，课上着上着就想到了浏览器，今天 Feedly 的朋友们又整什么活了吗 / GayHub 的朋友们又发现了什么新奇玩意儿吗？</p>
<p>也许让疫情背锅也不对，从安卓换到苹果之后生活改变了许多。自从一加 5 不再工作，我换上了一年前买给妈妈备用的 iPhone 6s，在这个三摄四摄呼风唤雨、苹果华为针尖麦芒的时代，手里握着这轻巧的 6s 可谓复古了。折腾了许久，翻越高墙的梦想还是不能在 6s 上实现，想了想被我刷成白苹果的 i7 我还是不再考虑瞎折腾了，翻什么翻？憋着！用惯了 Android 的我看来 iOS 还是不适合我，最让我头疼的是复制文件居然还必须走 iTunes，啊这？也许正是这些不习惯，让我戒掉了对手机的过度依赖，然后，转向了对电脑的过度依赖。在家有网有电，不像在宿舍玩到正尽兴时断网断电了，我的电脑也渐渐开始像一台服务器一样工作，白天网课、浏览器、VSCode，夜晚下载、挂机、自动更新，只有我哪天突然心疼本本了才会选择让他重启。原来花在手机游戏上的时间开始成为我瞎折腾的资本，这段时间除了上网课的时间我几乎都花在了浏览网页和写 Bug 上。重拾 C 语言，看看 Python，学学 CSS 和 JavaScript，想干啥就干啥，不像在宿舍。在宿舍里写代码有一种异类的感觉，我更希望大家在寝室一起联机快乐，而不是我在做着他们都不理解的事情然后他们发出不明所以的吹捧「牛逼啊」。</p>
<p>又或者这一切既不是因为疫情，也不是因为手机电脑，而是因为身边的人和事。今年过年的时候格外冷清，我觉得似乎上了大学之后这样的年就成为常态了，不像以前叔伯姨舅都会回家团聚，今年刚好就着疫情的由头谁也不回了，大年夜只剩一家五口围着咕嘟嘟冒泡的清汤火锅抿一口健康的王老吉，清心寡欲。二姑走了很多年了，家里人一直瞒着爷爷，刚开始的时候我看着父母亲朋在饭桌上编理由糊弄老人，现在爷爷似乎也不再问起，我对这事感觉很微妙。现在二姑爷也病的不轻了，我不敢想象以后的事。最近呢，舅舅也不知道什么情况住院了，从县里转到市里，妈妈不跟我说，但是我看着她时常精神不振就知道舅舅一定病得不轻。想想舅舅那么爽朗乐观的人，现在也不得不戴着呼吸机躺在病床上，这种感觉也很 <del>微妙</del> 不妙。妈妈就这件事时常警告我不要熬夜，要我早睡早起吃早饭。我也想过啊，可是有的事情成为习惯就不想改了，夜晚宁静得有种与世隔绝的感觉，做什么都不会被人打扰，没有 QQ 消息，没有微信通知，群聊变得安静，整个世界都变得清净了。这个时候开始，无论是突击作业还是敲击键盘写博文修代码，总是感觉十分舒适。哦，唯一让我头疼的就是妈妈的催促「几点啦？赶快睡觉啊」……</p>
<p>谈及生命的时候我总会想自己的未来。不知不觉大二也已经快过完了，曾经幻想中的步入社会就在眼前，可是当我走到这一步的时候却发现，我为了这一切做的事这么傻。我在父母的监督下学习，在大学的宽松下放肆，以前每天的学习就为了考一个像样的大学离开家乡，现在每天的学习就为了及格万岁。大一的时候认为这些数学物理学了又有什么用处呢？不学！现在接触了专业课才懂得什么叫「数理基础」，原来一切需要这些基础。那些年少无知的想法让现在的自己追悔莫及，一种 <em>多年的义务教育都将葬送在大学四年</em> 的想法在心底滋生。刚进入大学的时候我以自己接触了博客而自豪，现在却觉得这么多年了我的长进是那么微不足道，我总是三分钟热度学个皮毛就弃坑，而别人自学一周也许就能比我更懂 Web。身边的人就像这样默默的超越了我，只有我还活在从前。我觉得迷茫，我的人生漫无目的：未来会成为硕士吗？可是我的专业课学的一言难尽；未来会成为电气工程师吗？可是我似乎连电路仿真都做不明白；未来会成为程序员吗？可是我连前端三件套都没熟练掌握。当我否定掉这三个规划的时候，我便恐慌起来，我的人生就此失去目标了。一旦毕业我连找父母要钱的理由都没有，我从来没有考虑过如何生活。小的时候我觉得生活不过就是毕业了找份工作拿着几千一月的薪水，找个住的地方日复一日。现在看来那样的话真是糟糕透了：几千一月糊弄自己还差不多，父母呢？我有什么脸面让父母继续卖命？爱情呢？这样糟糕的糙汉子只有梦里才配拥有爱情吧？</p>
<h2 id="代码">代码</h2>
<p>太糟糕了，还是谈谈现在吧。学习之余便是代码，这一段是最近在 GitHub 上的「工作」。大约一两个月前我突然对吃灰已久的 GitHub 账号产生了想法：让 Contributions 绿起来！一直以来 GitHub 是我找资源的首选地，各种 Gist 和仓库，总是有相关的资源可以借鉴，前段时间折腾 WSL 的时候 Github issue 和 wiki 区一度成为我反复翻阅的地方，和 Stack Overflow 类似的，这里能找到大部分合适的答案。回到「工作」上来，最近做的事就是修改 VOID 主题了（顺便的还对 AlanDecode 大大的主题配套插件也动了刀，目前自己用起来是舒服了），虽然博客挺长时间没有更新了，但是对 VOID 的二次开发却一直未间断，甚至还像模像样的发布了两个小 Release。Git 的基本操作也学会一些，至少 clone commit push 一条龙算是熟练了。可惜，JavaScript 和 PHP 方面我一直都是萌新，甚至从未仔细学过他们的语法，这导致我的二次开发效率蛮低的，很多地方都是仿写，想做到没有冗余代码的地步我觉得我还有很长的路要走。本来是以为二次开发不久我就能在博客开心的宣布：VOID Done! 快来 Star 吧！结果随着二次开发的进行我越来越觉得我的代码写的实在太差劲了，为什么这个功能我做不出来？为什么这个功能要插件？现在，我连在 Alan 大佬的博客评论的勇气都没有了。（Alan：啊这？我原来写的这么工整规范的代码你给我改出个这玩意儿？）每每想到这我就一咬牙，绝对不能把这东西发博客，太 der 了！</p>
<p>真正自己做着主题维护的事情的时候，我就开始看开一些事情了。为什么开发者不回答我这个问题？我给你 5 块你把这个功能加到主题上好不好？博主博主你这个页面是怎么设置的啊？这个代码直接替换吗？换友链吗？在？…… 每天逛博客逛 GitHub 逛主题售后唠嗑群，我都能看见各种问题，至少 QQ 群里的问题层次其实都比较低，有的连问题是什么都描述不清楚。这大概是为什么 QQ 联系在程序员界算是被嫌弃的一个原因吧。被提问的人是什么感觉这因人而异，但是对我而言，我就觉得：这个问题很难吗？你自己动手试一下不好吗？同样打字的时间，你花在搜索引擎上效果比在这一两百人群只有几十个活人的地方效果更差吗？还有对于在主题售后群里聊 DD、cc、翻越高墙、散布链接的行为我更是深恶痛绝，几乎我加的每一个 QQ 主题群（从最初的 Material 到 Handsome 再到泽泽社长的群）都免不了这些。恶意攻击也偶有发生，但是链接还是会继续散布。主题售后群里时不时就丢链接的博客质量参差不齐，毫无意义的搬运不在少数。用点心思在文章上自然有人爱看，这道理很难懂吗？在这里只想借用 Alan 大佬发布 VOID 主题时的一段话：</p>
<blockquote>
<p>我希望使用这些主题的博主，能认真地多写几篇正经文章，这才是独立博客的精髓。一两句话的牢骚，大可以去微博与 Twit­ter 上说；花花绿绿的代刷广告与盗版采集还是免了吧。 [^1]</p>
</blockquote>
<p>当然，我也并不是一个优秀的博主，翻看我的归档就知道其实文章都是一些大佬看不上眼的东西，有的时候文章不删反而更容易激励自己，大概类似「反面教材」的效果。到 2024 年，如果这个博客还继续产出的话，我想必会回顾这十年的历程，从最初到当下审视博客的变化。说到十年我又想到了一个叫做「<a href="https://foreverblog.cn/">十年之约</a>」的项目，「从加入这个活动起，我们的博客十年不关闭，保持更新和活力」。对我而言，不需要任何「约定」「承诺」，我也会保持这份写博客的热情。实在是很难想象我这样一个三分钟热度的人居然坚持做博客这么多年几乎未间断！我十分期待有一天不再需要谷歌、不再需要过滤脚本，在地址栏输入中文，大家就能轻松获得详尽的中文资料。（记录一些最近发现的我觉得很棒的博客 [^2]）</p>
<h2 id="网络">网络</h2>
<p>谈及互联网内容，最近的瓜真是令人无语。什么 AO3、罗志祥、papi 酱…… 我真是搞不懂了，疫情期间闲着没事干是吗？有的事情确实挺令人恶心的，但是吃瓜归吃瓜，拿关注明星污点、翻黑料、瞎打拳的时间花在改善自己生活上不香吗？明星终究是明星，就算我拿着相机怼到人家脸上拍到了照片，咱们的世界也是截然不同的两个世界，非要说有点联系也是虚无缥缈的。</p>
<p>以前，这些明星黑料的生产商是微博，和我的世界很远；后来 QQ 有了看点，不过还好，可以关闭；现在，连哔哩哔哩也变味了。<del>我不知道是我的个人原因还是怎么了，</del> 我的哔哩哔哩她十分不像从前了。不谈每天推荐的某某正式入驻辣，连每天热门的榜单也五花八门，有的时候我刷新半天又半天都找不到一个对胃口的视频。我甚至下载了以前不屑一顾的抖音来消遣刷不到哔哩哔哩趣味的时间。</p>
<p>就我个人来看，哔哩哔哩开始走上一条悄悄远离二次元的路了，不管是公司高层的战略决策还是国家的隐形政策，她的确开始「变化」了。要说从什么时候开始有这种端倪，我觉得是央视表扬哔哩哔哩之后。舆论让哔哩哔哩越来越意识到自己其实有潜力做一个不只局限在二次元的公司，于是「变化」产生了。怎么说呢，我并没有觉得这样不好，但是就我自己看到的内容质量而言我觉得情况不太乐观。</p>
<p>说到这，我想到了哔哩哔哩弹幕的问题。弹幕弥补了视频中的不足，也拉进制作者与看官的距离，实在是高明的设计。但是低质弹幕却让人头疼，试问人们对二次元负面的一些刻板印象是从何而来？我觉得低质弹幕难辞其咎。关键词屏蔽能解决一些，但我还是希望从根源、从用户意愿上解决问题。随着社区规模的扩大，如何界定和规范用户行为，也应该成为视频平台用心考虑的问题。B 站风纪委员会希望能做得更好。哔哩哔哩的变化我觉得很大一部分都是因为涌入这个社区的人，规模扩大但不应该降低门槛，降低门槛不应该下限太低，如何找到一个平衡点让用户质量和社区热度都得到保证是一个难题。</p>
<blockquote>
<p>破案了，哔哩哔哩还是从前那个哔哩哔哩，我不是从前那个我了。</p>
</blockquote>
<h2 id="end">End</h2>
<p>写写停停，一篇普通的日记花了三个多小时，又是一次无意义的写作。</p>
<p>写完再看一遍觉得结构实在是糟糕，但是又不知道从何理出一条线索来，索性就着 Markdown 标题简单提炼了一下。脑袋里装的稀奇古怪的想法没有什么人值得我倾诉，家人亦是如此，所以还是写到博客里痛快。以前手写日记的感觉很难再找到了，敲击键盘比拿出纸笔似乎更加容易，尽管如此我还是不知道下一次日记会写在什么时候。一切随缘吧！</p>
<p>[^1]: 《<a href="https://blog.imalan.cn/archives/247/">VOID：现在可以公开的情报 - 无文字|三无计划</a>》
[^2]: <a href="https://beyondstars.xyz/">@探索子</a> <a href="https://www.mina.moe/">@MiNa!</a> <a href="https://blog.ichr.me/">@ChrAlpha 的幻想乡</a></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Mark 并调试 HEU 自动打卡代码]]></title>
            <link>https://blog.monsterx.cn/code/heu-auto-checkin-covid19/</link>
            <guid>https://blog.monsterx.cn/code/heu-auto-checkin-covid19/</guid>
            <pubDate>Sun, 05 Apr 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>最近这几天又不知道干点啥，天天上课累死了，前面的还没掌握就又要接新的知识，真是太难了。心血来潮想好好学一下 JavaScript 什么的前端基础，找资料逛博客的时候碰巧发现了一个学长的博客，看到《<a href="https://zjw1.top/2020/03/10/auto_checkin_during_covid19_and_cas_sso_learning/">疫情期间自动健康打卡暨 CAS 单点登录认证实践 - SiteForZJW</a>》这篇文章，常年起不来床的我赶紧点开了，啊啊啊我为什么没有早点发现这种好东西啊，生气。</p>
<p>第一次看的时候了解到这个 Python 代码要自己先手动执行一边获取表单数据。Emmm，那是啥，好像不太了解呢，先 Mark 了！</p>
<h2 id="python-和依赖">Python 和依赖</h2>
<p>什么？你说这个年头还有人电脑上没装 Python？なんと！</p>
<p>Windows 系统直接上 Python 官网下载安装包，注意将 Python 安装目录添加到 PATH 环境变量，一并安装 pip。如果运行时显示缺少模块就 pip 安装一下。</p>
<pre><code class="language-bash">python -m pip install --upgrade pip
pip install requests lxml</code></pre>
<h2 id="获取-form-data">获取 form Data</h2>
<p>今天早上起来的出奇的早（7 点半我就醒了），一想到学校的打卡十点前就要完成，我突然想到了那个自动打卡、表单数据的事情。于是我点开了浏览器开始尝试。</p>
<p>打开 <a href="http://one.hrbeu.edu.cn/infoplus/form/JKXXSB/start">网上办事中心 - 平安行动</a> ，虽然不知道是啥，但 F12 肯定会告诉我的。选择 Network 栏，网页从打开这个菜单后加载的所有请求都会在这里显示，先刷新一遍网页，找了一遍好像什么也没有（一开始我以为表单数据是缓存下来的什么东西），Emmm，提交一遍试试，点完确认提交之后 Network 最下面显示了一个新的名叫 <code>doAction</code> 资源，那一定就是你了！<strong>注意此时不要点确定，点确定之后该资源会被刷新掉。</strong></p>
<p>好的，<code>Form Data</code> Get√ 。选择 <code>view parsed</code> <code>view decoded</code> 就能看到这个表单的所有数据，也就是之前 Python 自动打卡需要自定义的。完整存好 <code>formData</code> <code>boundFields</code> 的内容。</p>
<p><img src="https://blog.monsterx.cn/code/heu-auto-checkin-covid19/images/post/heu-checkin1.png" alt="Network"><img src="https://blog.monsterx.cn/code/heu-auto-checkin-covid19/images/post/heu-checkin2.png" alt="doAction - Form Data"></p>
<h2 id="调试">调试</h2>
<p>表单数据有了，开始调试 Python 。</p>
<h3 id="邮件提醒">邮件提醒</h3>
<p>源代码最后的发送邮件部分需要自行引用发送邮件的 <code>.py</code> 文件，但是谷歌找到的好几个 <code>sendmail.py</code> 补上去之后都有奇怪的报错，比如 <code>if</code> 条件右括号报语法错误，我明明是直接复制的啊 QaQ ，看了好几遍也不应该有错啊（后来发觉可能是 Python 版本问题）。最终我索性直接搜 Python SMTP 的用法，找了一段代码补上去。</p>
<p>在 Linux 下试运行的时候发现打卡段没问题，但是后面邮件发送这段报错：</p>
<pre><code class="language-powershell">Traceback (most recent call last):
  File &quot;checkin.py&quot;, line 151, in &lt;module&gt;
    smtpObj.connect(mail_host, 25)    # 25 为 SMTP 端口号
  File &quot;/usr/lib64/python3.6/smtplib.py&quot;, line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File &quot;/usr/lib64/python3.6/smtplib.py&quot;, line 307, in _get_socket
    self.source_address)
  File &quot;/usr/lib64/python3.6/socket.py&quot;, line 724, in create_connection
    raise err
  File &quot;/usr/lib64/python3.6/socket.py&quot;, line 713, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out</code></pre>
<p>搜索了一圈发现 Linux 下 SMTP 发信加密程度要求更高，所以得加密发信，将原来的发信替换为 SSL 加密发信：</p>
<pre><code class="language-python">smtpObj = smtplib.SMTP_SSL() 
smtpObj.connect(mail_host, 465)      # 一般加密发信 smtp 端口号为 465</code></pre>
<p>在 3.7 版本以上的 Python 中需要此脚本时必须使用 <code>smtpObj = smtplib.SMTP_SSL(mail_host)</code> ，否则邮件发信会报错 ValueError 如下：</p>
<pre><code class="language-powershell">Traceback (most recent call last):
  File &quot;/home/Project/Python/HEUCheckin-2018041015.py&quot;, line 170, in &lt;module&gt;
    smtpObj.connect(mail_host, 465)       # 加密时 SMTP 端口号为 465
  File &quot;/usr/local/Python3.8.2/lib/python3.8/smtplib.py&quot;, line 339, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File &quot;/usr/local/Python3.8.2/lib/python3.8/smtplib.py&quot;, line 1042, in _get_socket
    new_socket = self.context.wrap_socket(new_socket,
  File &quot;/usr/local/Python3.8.2/lib/python3.8/ssl.py&quot;, line 500, in wrap_socket
    return self.sslsocket_class._create(
  File &quot;/usr/local/Python3.8.2/lib/python3.8/ssl.py&quot;, line 1031, in _create
    self._sslobj = self._context._wrap_socket(
ValueError: server_hostname cannot be an empty string or start with a leading dot.</code></pre>
<h3 id="关闭代理">关闭代理</h3>
<p>本地调试的时候，由于我平时习惯开 Clash 代理挂着，没注意这个，结果就报错了，信息如下：</p>
<details><summary><strong>Python Traceback</strong></summary><br />


<pre><code class="language-powershell">Traceback (most recent call last):
  File &quot;D:\Python\Python38-64\lib\site-packages\urllib3\connectionpool.py&quot;, line 665, in urlopen
    httplib_response = self._make_request(
  File &quot;D:\Python\Python38-64\lib\site-packages\urllib3\connectionpool.py&quot;, line 421, in _make_request
    six.raise_from(e, None)
  File &quot;&lt;string&gt;&quot;, line 3, in raise_from
  File &quot;D:\Python\Python38-64\lib\site-packages\urllib3\connectionpool.py&quot;, line 416, in _make_request
    httplib_response = conn.getresponse()
  File &quot;D:\Python\Python38-64\lib\http\client.py&quot;, line 1322, in getresponse
    response.begin()
  File &quot;D:\Python\Python38-64\lib\http\client.py&quot;, line 303, in begin
    version, status, reason = self._read_status()
  File &quot;D:\Python\Python38-64\lib\http\client.py&quot;, line 272, in _read_status
    raise RemoteDisconnected(&quot;Remote end closed connection without&quot;
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;D:\Python\Python38-64\lib\site-packages\requests\adapters.py&quot;, line 439, in send
    resp = conn.urlopen(
  File &quot;D:\Python\Python38-64\lib\site-packages\urllib3\connectionpool.py&quot;, line 719, in urlopen
    retries = retries.increment(
  File &quot;D:\Python\Python38-64\lib\site-packages\urllib3\util\retry.py&quot;, line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#39;127.0.0.1&#39;, port=7890): Max retries exceeded with url: http://cas.hrbeu.edu.cn/cas/login?service=http%3A%2F%2Fjkgc.hrbeu.edu.cn%2Finfoplus%2Flogin%3FretUrl%3Dhttp%253A%252F%252Fjkgc.hrbeu.edu.cn%252Finfoplus%252Fform%252FJSXNYQSBtest%252Fstart%253Fticket%253DST-3779417-6SDr7iRPSkJxSd3MFyNd-cas01.example.org (Caused by ProxyError(&#39;Cannot connect to proxy.&#39;, RemoteDisconnected(&#39;Remote end closed connection without response&#39;)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;d:/workshop/PythonProject/CheckIn/checkin.py&quot;, line 61, in &lt;module&gt;
    response302 = sesh.post(req.url, data=user_form, headers=headers)
  File &quot;D:\Python\Python38-64\lib\site-packages\requests\sessions.py&quot;, line 578, in post
    return self.request(&#39;POST&#39;, url, data=data, json=json, **kwargs)
  File &quot;D:\Python\Python38-64\lib\site-packages\requests\sessions.py&quot;, line 530, in request
    resp = self.send(prep, **send_kwargs)
  File &quot;D:\Python\Python38-64\lib\site-packages\requests\sessions.py&quot;, line 665, in send
    history = [resp for resp in gen] if allow_redirects else []
  File &quot;D:\Python\Python38-64\lib\site-packages\requests\sessions.py&quot;, line 665, in &lt;listcomp&gt;
    history = [resp for resp in gen] if allow_redirects else []
  File &quot;D:\Python\Python38-64\lib\site-packages\requests\sessions.py&quot;, line 237, in resolve_redirects
    resp = self.send(
  File &quot;D:\Python\Python38-64\lib\site-packages\requests\sessions.py&quot;, line 643, in send
    r = adapter.send(request, **kwargs)
  File &quot;D:\Python\Python38-64\lib\site-packages\requests\adapters.py&quot;, line 510, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPConnectionPool(host=&#39;127.0.0.1&#39;, port=7890): Max retries exceeded with url: http://cas.hrbeu.edu.cn/cas/login?service=http%3A%2F%2Fjkgc.hrbeu.edu.cn%2Finfoplus%2Flogin%3FretUrl%3Dhttp%253A%252F%252Fjkgc.hrbeu.edu.cn%252Finfoplus%252Fform%252FJSXNYQSBtest%252Fstart%253Fticket%253DST-3779417-6SDr7iRPSkJxSd3MFyNd-cas01.example.org (Caused by ProxyError(&#39;Cannot connect to proxy.&#39;, RemoteDisconnected(&#39;Remote end closed connection without response&#39;)))</code></pre>
</details><br />


<p>报错一大堆没怎么看懂，<code>ProxyError</code> 看来应该是代理问题，可能和主机的网络设置有关系，没有深究原因，所以解决方案就是 <strong>关掉代理</strong> ！</p>
<blockquote>
<p>尝试了在运行前用 <code>export</code> 或者 <code>set</code> 命令设置 <code>http_proxy</code> <code>https_proxy</code> 代理，也一样无法使用。</p>
</blockquote>
<h3 id="结果判定">结果判定</h3>
<p>调试时还发现个问题，原代码打卡出错的判定有缺陷，只报 Python 脚本出 Exception 时的错，而提交表单时可能成功提交，但是返回的不是打卡成功，而是打卡失败。那么如何判断打卡提交正常但是打卡失败呢，这里关注返回的数据 <code>response_end</code> ，用 requests 库转换成 text 后的 <code>response_end.text</code> 缩进一下长这个样子：</p>
<pre><code class="language-json"># 成功时
{
  &quot;errno&quot;:0,
  &quot;ecode&quot;:&quot;SUCCEED&quot;,
  &quot;entities&quot;:[{
    &quot;stepId&quot;:2,
    &quot;name&quot;:&quot;办结&quot;,
    &quot;code&quot;:&quot;autoStep1&quot;,&quot;status&quot;:0,&quot;type&quot;:&quot;Auto&quot;,&quot;flowStepId&quot;:0,&quot;executorSelection&quot;:0,&quot;timestamp&quot;:0,&quot;posts&quot;:[],&quot;users&quot;:[],&quot;parallel&quot;:false,&quot;hasInstantNotification&quot;:false,&quot;hasCarbonCopy&quot;:false,&quot;entryId&quot;:2797847,&quot;entryStatus&quot;:0,&quot;entryRelease&quot;:false
  }]
}

# 失败时
{
  &quot;errno&quot;:22001,
  &quot;ecode&quot;:&quot;EVENT_CANCELLED&quot;,
  &quot;error&quot;:&quot;发生异常\n\njava.lang.reflect.InvocationTargetException\n\tat sun.reflect.GeneratedMethodAccessor457.invoke(Unknown Source)\n\t...\n&quot;,
  &quot;entities&quot;:[]
}</code></pre>
<p>可以看到返回的字段中 <code>errno</code> 为 <code>0</code> 代表成功提交，剩下的 <code>ecode</code> 显示 <code>str</code> 型的状态，<code>error</code> 只有出现错误时才有，包含了所有的错误信息，这个错误是在学校服务器上报的，不是本地脚本的问题。<code>entities</code> 包含成功提交后的一些数据。那么这就用 <code>errno</code> 来判定远程提交后返回是否成功。先使用 <code>json.loads()</code> 将其转换为 JSON 格式，注意在返回的数据中 <code>errno</code> 字段为 <code>int</code> 类型，<code>entities</code> 字段为 <code>list</code> 类型，发信的 <code>msg</code> 要用 <code>str()</code> 转换这两个数据。</p>
<p>实现代码如下：</p>
<pre><code class="language-python">try:
    # ......

    response_end = sesh.post(submit_url, data=submit_form, headers=headers)
    resJson = json.loads(response_end.text)

    print(&#39;Form url: &#39;, form_response.url)
    # print(&#39;Form status: &#39;, response_end.text)
    print(&#39;Form Status: &#39;, resJson[&#39;ecode&#39;])
    print(&#39;Form stJson: &#39;, resJson)
    # 获取表单返回 Json 数据所有 key 用这个
    # print(&#39;Form stJsonkey: &#39;, resJson.keys())

    # 加入远程提交返回结果判断
    if (resJson[&#39;errno&#39;] == 0):
        print(&#39;Form Succeed: &#39;, resJson[&#39;ecode&#39;])
        title = f&#39;打卡成功 &lt;{submit_form[&quot;stepId&quot;]}&gt;&#39;
        msg = &#39;\t表单地址: &#39; + form_response.url + &#39;\n\n\t表单状态: \n\t\terrno：&#39; + str(resJson[&#39;errno&#39;]) + &#39;\n\t\tecode：&#39; + str(resJson[&#39;ecode&#39;]) + &#39;\n\t\tentities：&#39; + str(resJson[&#39;entities&#39;]) + &#39;\n\n\n\t完整返回：&#39; + response_end.text
    else:
        print(&#39;Form Error: &#39;, resJson[&#39;ecode&#39;])
        title = f&#39;打卡失败！校网出错&#39;
        msg = &#39;\t表单地址: &#39; + form_response.url + &#39;\n\n\t错误信息: \n\t\terrno：&#39; + str(resJson[&#39;errno&#39;]) + &#39;\n\t\tecode：&#39; + str(resJson[&#39;ecode&#39;]) + &#39;\n\t\tentities：&#39; + str(resJson[&#39;entities&#39;]) + &#39;\n\n\n\t完整返回：&#39; + response_end.text
except:
    print(&#39;\n:.:.:.:.: Except return :.:.:.:.:&#39;)
    err = traceback.format_exc()
    print(&#39;Python Error: \n&#39;, err)
    title = &#39;打卡失败！脚本出错&#39;
    msg = &#39;\t脚本报错: \n\n\t&#39; + err</code></pre>
<p>好啦，现在就差不多完美了，唯一美中不足的就是没有加入 <code>retry</code> 的功能，还不了解这个怎么实现，有空可以试试。</p>
<h2 id="完工">完工</h2>
<details><summary><strong>修补完整的 auto-checkin.py</strong></summary><br />


<pre><code class="language-python">#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

&quot;&quot;&quot;
平安行动自动打卡

Created on 2020-04-13 20:20
@author: ZhangJiawei &amp; Monst.x
&quot;&quot;&quot;

import requests
import lxml.html
import re
import json
import random
import time
import smtplib
import traceback

headers = {
    &quot;Accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9&quot;,
    &quot;Accept-Encoding&quot;: &quot;gzip, deflate, br&quot;,
    &quot;Accept-Language&quot;: &quot;zh-CN&quot;,
    &quot;Cache-Control&quot;: &quot;max-age=0&quot;,
    &quot;Connection&quot;: &quot;keep-alive&quot;,
    &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;,
    &quot;Cookie&quot;: &quot;MESSAGE_TICKET=%7B%22times%22%3A0%7D; &quot;,
    &quot;Host&quot;: &quot;cas.hrbeu.edu.cn&quot;,
    &quot;Referer&quot;: &quot;https://cas.hrbeu.edu.cn/cas/login?service=http%3A%2F%2Fjkgc.hrbeu.edu.cn%2Finfoplus%2Flogin%3FretUrl%3Dhttp%253A%252F%252Fjkgc.hrbeu.edu.cn%252Finfoplus%252Fform%252FJSXNYQSBtest%252Fstart&quot;,
    &quot;Upgrade-Insecure-Requests&quot;: &quot;1&quot;,
    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.18362&quot;
}

data = {
    &quot;username&quot;:&quot;studentNumber&quot;,                # 学号
    &quot;password&quot;:&quot;password&quot;                      # 教务处密码
}
def findStr(source, target):
    return source.find(target) != -1
title = &quot;&quot;
msg = &quot;&quot;

try:
    #get
    url_login = &#39;https://cas.hrbeu.edu.cn/cas/login?service=http%3A%2F%2Fjkgc.hrbeu.edu.cn%2Finfoplus%2Fform%2FJSXNYQSBtest%2Fstart&#39;
    print(&quot;Begin to login ...&quot;)
    sesh = requests.session()
    req = sesh.get(url_login)
    html_content = req.text

    #post
    login_html = lxml.html.fromstring(html_content)
    hidden_inputs=login_html.xpath(r&#39;//div[@id=&quot;main&quot;]//input[@type=&quot;hidden&quot;]&#39;)
    user_form = {x.attrib[&quot;name&quot;] : x.attrib[&quot;value&quot;] for x in hidden_inputs}

    user_form[&quot;username&quot;]=data[&#39;username&#39;]
    user_form[&quot;password&quot;]=data[&#39;password&#39;]
    user_form[&quot;captcha&quot;]=&#39;&#39;
    user_form[&quot;submit&quot;]=&#39;登 录&#39;
    headers[&#39;Cookie&#39;] = headers[&#39;Cookie&#39;] + req.headers[&#39;Set-cookie&#39;]

    req.url = f&#39;https://cas.hrbeu.edu.cn/cas/login;jsessionid={req.cookies.get(&quot;JSESSIONID&quot;)}?service=http%3A%2F%2Fjkgc.hrbeu.edu.cn%2Finfoplus%2Fform%2FJSXNYQSBtest%2Fstart&#39;
    response302 = sesh.post(req.url, data=user_form, headers=headers)
    casRes = response302.history[0]
    print(&quot;CAS response header&quot;, findStr(casRes.headers[&#39;Set-Cookie&#39;],&#39;CASTGC&#39;))

    #get
    jkgc_response = sesh.get(response302.url)

    #post
    headers[&#39;Accept&#39;] = &#39;*/*&#39;
    headers[&#39;Cookie&#39;] = jkgc_response.request.headers[&#39;Cookie&#39;]
    headers[&#39;Host&#39;] = &#39;jkgc.hrbeu.edu.cn&#39;
    headers[&#39;Referer&#39;] = jkgc_response.url
    jkgc_html = lxml.html.fromstring(jkgc_response.text)
    csrfToken = jkgc_html.xpath(r&#39;//meta[@itemscope=&quot;csrfToken&quot;]&#39;)
    csrfToken = csrfToken.pop().attrib[&quot;content&quot;]
    jkgc_form = {
        &#39;idc&#39;: &#39;JSXNYQSBtest&#39;,
        &#39;release&#39;: &#39;&#39;,
        &#39;csrfToken&#39;: csrfToken,
        &#39;formData&#39;: {
            &#39;_VAR_URL&#39;: jkgc_response.url,
            &#39;_VAR_URL_Attr&#39;: {
                &#39;ticket&#39;: re.match(r&#39;.*ticket=(.*)&#39;, jkgc_response.url).group(1)
            }
        }
    }
    jkgc_form[&#39;formData&#39;] = json.dumps(jkgc_form[&#39;formData&#39;])
    jkgc_url = &#39;http://jkgc.hrbeu.edu.cn/infoplus/interface/start&#39;
    response3 = sesh.post(jkgc_url, data=jkgc_form, headers=headers)

    #get
    form_url = json.loads(response3.text)[&#39;entities&#39;][0]
    form_response = sesh.get(form_url)

    #post
    headers[&#39;Accept&#39;] = &#39;application/json, text/javascript, */*; q=0.01&#39;
    headers[&#39;Referer&#39;] = form_url
    headers[&#39;X-Requested-With&#39;] = &#39;XMLHttpRequest&#39;
    submit_url = &#39;http://jkgc.hrbeu.edu.cn/infoplus/interface/doAction&#39;

    submit_html = lxml.html.fromstring(form_response.text)
    csrfToken2 = submit_html.xpath(r&#39;//meta[@itemscope=&quot;csrfToken&quot;]&#39;)
    csrfToken2 = csrfToken2.pop().attrib[&quot;content&quot;]

    submit_form = {
        &#39;actionId&#39;: &#39;1&#39;,
        # boundFields 修改位置
        &#39;boundFields&#39;: &#39;fieldCXXXdqszdjtx,fieldCXXXjtgjbc,...&#39;,
        &#39;csrfToken&#39;: csrfToken2,
        # formData 修改位置
        &#39;formData&#39;: r&#39;{&quot;_VAR_EXECUTE_INDEP_ORGANIZE_Name&quot;:&quot;学院&quot;,&quot;_VAR_ACTION_INDEP_ORGANIZES_Codes&quot;:&quot;xxxxx&quot;,...}&#39;,
        &#39;lang&#39;: &#39;zh&#39;,
        &#39;nextUsers&#39;: &#39;{}&#39;,
        &#39;rand&#39;: str(random.random() * 999),
        &#39;remark&#39;: &#39;&#39;,
        &#39;stepId&#39;: re.match(r&#39;.*form/(\d*?)/&#39;,form_response.url).group(1),
        &#39;timestamp&#39;: str(int(time.time()+0.5))
    }
    response_end = sesh.post(submit_url, data=submit_form, headers=headers)
    resJson = json.loads(response_end.text)

    ## 表单填写完成，返回结果
    print(&#39;Form url: &#39;, form_response.url)
    # print(&#39;Form status: &#39;, response_end.text)
    print(&#39;Form Status: &#39;, resJson[&#39;ecode&#39;])
    print(&#39;Form stJson: &#39;, resJson)
    # 获取表单返回 Json 数据所有 key 用这个
    # print(&#39;Form stJsonkey: &#39;, resJson.keys())

    if (resJson[&#39;errno&#39;] == 0):
        print(&#39;Form Succeed: &#39;, resJson[&#39;ecode&#39;])
        title = f&#39;打卡成功 &lt;{submit_form[&quot;stepId&quot;]}&gt;&#39;
        msg = &#39;\t表单地址: &#39; + form_response.url + &#39;\n\n\t表单状态: \n\t\terrno：&#39; + str(resJson[&#39;errno&#39;]) + &#39;\n\t\tecode：&#39; + str(resJson[&#39;ecode&#39;]) + &#39;\n\t\tentities：&#39; + str(resJson[&#39;entities&#39;]) + &#39;\n\n\n\t完整返回：&#39; + response_end.text
    else:
        print(&#39;Form Error: &#39;, resJson[&#39;ecode&#39;])
        title = f&#39;打卡失败！校网出错&#39;
        msg = &#39;\t表单地址: &#39; + form_response.url + &#39;\n\n\t错误信息: \n\t\terrno：&#39; + str(resJson[&#39;errno&#39;]) + &#39;\n\t\tecode：&#39; + str(resJson[&#39;ecode&#39;]) + &#39;\n\t\tentities：&#39; + str(resJson[&#39;entities&#39;]) + &#39;\n\n\n\t完整返回：&#39; + response_end.text
except:
    print(&#39;\n:.:.:.:.: Except return :.:.:.:.:&#39;)
    err = traceback.format_exc()
    print(&#39;Python Error: \n&#39;, err)
    title = &#39;打卡失败！脚本出错&#39;
    msg = &#39;\t脚本报错: \n\n\t&#39; + err
finally:
    print(&#39;\n:.:.:.:.: Finally :.:.:.:.:&#39;)
    ## 发送邮件
    # import sendmail     ## 这个是普通.py文件，不是Python库
    # sendmail.sendmail(title, msg)

    from email.mime.text import MIMEText
    from email.header import Header

    # 第三方 SMTP 服务
    mail_host=&quot;smtp.exmail.qq.com&quot;                 # 设置 smtp 服务器
    mail_user=&quot;example@example.com&quot;                # smtp 发信邮箱用户名
    mail_pass=&quot;emailpassword&quot;                      # smtp 发信邮箱密码
    sender = &#39;1@example.com&#39;                       # 发信邮箱显示
    receivers = [&#39;2@example.com&#39;]                  # 修改为收件人邮箱，多邮箱以数组形式写
    message = MIMEText(msg, &#39;plain&#39;, &#39;utf-8&#39;)
    message[&#39;From&#39;] = Header(&quot;1@example.com&quot;, &#39;utf-8&#39;)        # 发件人邮箱
    message[&#39;To&#39;] =  Header(&quot;2@example.com&quot;, &#39;utf-8&#39;)         # 收件人邮箱
    subject = title
    message[&#39;Subject&#39;] = Header(subject, &#39;utf-8&#39;)
    try:
        # smtpObj = smtplib.SMTP()              # 使用一般发信
        # smtpObj.connect(mail_host, 25)        # 不加密时 SMTP 端口号为 25
        # smtpObj = smtplib.SMTP_SSL()          # Python 3.7 以下版本 SSL 加密发信
        smtpObj = smtplib.SMTP_SSL(mail_host)   # Python 3.7 及以上版本 SSL 加密发信
        smtpObj.connect(mail_host, 465)         # 加密时 SMTP 端口号为 465
        smtpObj.login(mail_user,mail_pass)
        smtpObj.sendmail(sender, receivers, message.as_string())
        print (&quot;Success: The email was sent successfully&quot;)
    except smtplib.SMTPException:
        print (&quot;Error: Can not send mail&quot;)</code></pre>
</details><br />


<p>合理地偷个懒，需要修改的地方都在代码注释里了。</p>
<h2 id="定时任务">定时任务</h2>
<p>要想让代码实现自动打卡，还需要另外设置定时任务，Linux 可以用 <strong>crontab</strong>，Windows 可以用 <strong>任务计划程序</strong>。</p>
<pre><code class="language-bash"># Linux 下添加 crontab 定时命令，每天 8:00 执行打卡并输出日志到 .log 文件
# 建议先运行测试是否可行
# python3 auto-checkin.py

crontab -e
0 8 * * * root /path/to/python3 /path/to/auto-checkin.py &gt; /path/to/checkin.log
# :wq 保存并退出</code></pre>
<p>Windows 下按 <code>win</code> 搜索“任务计划程序”调出菜单，然后在右栏选择创建基础任务。跟着创建基本任务向导的指示一步一步来就好了，「触发器 -&gt; 每日」设置时间推荐避开 6:00 腐败街预约打卡的高峰，8:00 就不错。「操作 -&gt; 启动程序」的程序或脚本项按下面格式填写。</p>
<p><img src="https://blog.monsterx.cn/code/heu-auto-checkin-covid19/images/post/heu-autotask.png" alt="Windows 定时任务设置"></p>
<p>Okay，睡个回笼觉庆祝一下 🥳..</p>
<blockquote>
<p>查看《<a href="https://blog.monsterx.cn/tech/modified-github-actions-4-heu-checkin/">照葫芦画瓢 · 编写 Actions 打卡工作流</a>》了解 GitHub Actions 版本。</p>
</blockquote>
]]></content:encoded>
        </item>
    </channel>
</rss>